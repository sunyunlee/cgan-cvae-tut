{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, label_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "#         self.input = nn.Linear(input_dim + label_dim, hidden_dim)\n",
    "        self.input = nn.Linear(input_dim, hidden_dim)\n",
    "#         self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        self.hidden = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.hidden3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        self.mu_z = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.std_z = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "#     def forward(self, x, label):\n",
    "    def forward(self, x):\n",
    "#         out = self.input(torch.cat((x, label), -1))\n",
    "        out = self.input(x)\n",
    "\n",
    "        out = self.hidden(out)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "#         out = self.dropout1(out)\n",
    "        \n",
    "#         out = self.hidden2(out)\n",
    "#         out = F.relu(out)\n",
    "        \n",
    "#         out = self.hidden3(out)\n",
    "#         out = F.relu(out)\n",
    "        \n",
    "        mu_z = self.mu_z(out)\n",
    "        std_z = self.std_z(out)\n",
    "\n",
    "        return mu_z, std_z\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, label_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "#         self.input = nn.Linear(latent_dim + label_dim, hidden_dim)\n",
    "        self.input = nn.Linear(latent_dim, hidden_dim)\n",
    "#         self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "        self.hidden = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.hidden3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.mu_x = nn.Linear(hidden_dim, output_dim)\n",
    "        self.std_x = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#     def forward(self, z, label):\n",
    "    def forward(self, z):\n",
    "#         out = self.input(torch.cat((z, label), -1))\n",
    "        out = self.input(z)\n",
    "\n",
    "        out = self.hidden(out)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "#         out = self.dropout1(out)\n",
    "        \n",
    "#         out = self.hidden2(out)\n",
    "#         out = F.relu(out)\n",
    "        \n",
    "#         out = self.hidden3(out)\n",
    "# #         out = self.bn3(out)\n",
    "#         out = F.relu(out)\n",
    "# #         out = self.dropout3(out)\n",
    "        \n",
    "        mu_x = self.mu_x(out)\n",
    "        std_x = self.std_x(out)\n",
    "\n",
    "        return mu_x, std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "bos = load_boston()\n",
    "df = pd.DataFrame(bos.data)\n",
    "df.columns = bos.feature_names\n",
    "print(len(bos.feature_names))\n",
    "df[\"Price\"] = bos.target\n",
    "\n",
    "data = df[df.columns[:-1]]\n",
    "# data = data.apply(\n",
    "#     lambda x: (x - x.mean()) / x.std()\n",
    "# )\n",
    "\n",
    "data[\"Price\"] = df.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Dataset to numpy\n",
    "X = torch.tensor(data.drop(\"Price\", axis=1).values).type(torch.float64)\n",
    "Y = torch.tensor(data[\"Price\"].values).type(torch.float64)\n",
    "\n",
    "# Split dataset for test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Standardize \n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = torch.tensor(scaler.transform(X_train)).type(torch.float64)\n",
    "X_test = torch.tensor(scaler.transform(X_test)).type(torch.float64)\n",
    "\n",
    "Y_train = Y_train.view(-1, 1)\n",
    "Y_test = Y_test.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(mu_z, std_z, z_sample, mu_x, std_x, x_in):\n",
    "    S = x_in.shape[0]\n",
    "    \n",
    "    # log posterior q(z|x)\n",
    "    q_z_dist = torch.distributions.Normal(mu_z, torch.exp(std_z))\n",
    "    log_q_z = q_z_dist.log_prob(z_sample)\n",
    "    \n",
    "    # log likelihood p(x|z)\n",
    "    p_x_dist = torch.distributions.Normal(mu_x, torch.exp(std_x))\n",
    "    log_p_x = p_x_dist.log_prob(x_in)\n",
    "    \n",
    "    # log prior \n",
    "    p_z_dist = torch.distributions.Normal(0, 1)\n",
    "    log_p_z = p_z_dist.log_prob(z_sample)\n",
    "    \n",
    "    loss = (1 / S) * (\n",
    "        torch.sum(log_q_z) - torch.sum(log_p_x) - torch.sum(log_p_z) \n",
    "    )\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "N_EPOCHS = 1200    # N_EPOCHS = 100 overfitted the data so the evaluation was very bad \n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001\n",
    "INPUT_DIM = X_train.shape[1]\n",
    "LABEL_DIM = Y_train.shape[1]\n",
    "LATENT_DIM = 2\n",
    "HIDDEN_DIM = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_iter = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(INPUT_DIM, LABEL_DIM, HIDDEN_DIM, LATENT_DIM).type(torch.float64)\n",
    "decoder = Decoder(LATENT_DIM, LABEL_DIM, HIDDEN_DIM, INPUT_DIM).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 1200] average loss: 25.597570\n",
      "Epoch [1 / 1200] test loss: 24.809198\n",
      "Epoch [2 / 1200] average loss: 24.051956\n",
      "Epoch [2 / 1200] test loss: 24.343946\n",
      "Epoch [3 / 1200] average loss: 23.603130\n",
      "Epoch [3 / 1200] test loss: 24.662345\n",
      "Epoch [4 / 1200] average loss: 25.084145\n",
      "Epoch [4 / 1200] test loss: 26.193193\n",
      "Epoch [5 / 1200] average loss: 23.519565\n",
      "Epoch [5 / 1200] test loss: 23.771573\n",
      "Epoch [6 / 1200] average loss: 23.498981\n",
      "Epoch [6 / 1200] test loss: 23.848869\n",
      "Epoch [7 / 1200] average loss: 22.829448\n",
      "Epoch [7 / 1200] test loss: 23.275625\n",
      "Epoch [8 / 1200] average loss: 23.026310\n",
      "Epoch [8 / 1200] test loss: 22.294343\n",
      "Epoch [9 / 1200] average loss: 22.744145\n",
      "Epoch [9 / 1200] test loss: 22.006438\n",
      "Epoch [10 / 1200] average loss: 22.425819\n",
      "Epoch [10 / 1200] test loss: 22.195646\n",
      "Epoch [11 / 1200] average loss: 22.202456\n",
      "Epoch [11 / 1200] test loss: 22.596498\n",
      "Epoch [12 / 1200] average loss: 21.925766\n",
      "Epoch [12 / 1200] test loss: 21.749838\n",
      "Epoch [13 / 1200] average loss: 21.743644\n",
      "Epoch [13 / 1200] test loss: 21.958396\n",
      "Epoch [14 / 1200] average loss: 22.424869\n",
      "Epoch [14 / 1200] test loss: 22.743298\n",
      "Epoch [15 / 1200] average loss: 22.173397\n",
      "Epoch [15 / 1200] test loss: 21.450149\n",
      "Epoch [16 / 1200] average loss: 21.212968\n",
      "Epoch [16 / 1200] test loss: 21.162382\n",
      "Epoch [17 / 1200] average loss: 21.094939\n",
      "Epoch [17 / 1200] test loss: 21.297574\n",
      "Epoch [18 / 1200] average loss: 21.191333\n",
      "Epoch [18 / 1200] test loss: 21.010314\n",
      "Epoch [19 / 1200] average loss: 20.808837\n",
      "Epoch [19 / 1200] test loss: 20.985731\n",
      "Epoch [20 / 1200] average loss: 20.738605\n",
      "Epoch [20 / 1200] test loss: 21.173500\n",
      "Epoch [21 / 1200] average loss: 20.807836\n",
      "Epoch [21 / 1200] test loss: 20.869805\n",
      "Epoch [22 / 1200] average loss: 20.671630\n",
      "Epoch [22 / 1200] test loss: 21.017672\n",
      "Epoch [23 / 1200] average loss: 20.602746\n",
      "Epoch [23 / 1200] test loss: 20.677117\n",
      "Epoch [24 / 1200] average loss: 20.230916\n",
      "Epoch [24 / 1200] test loss: 20.437983\n",
      "Epoch [25 / 1200] average loss: 20.196716\n",
      "Epoch [25 / 1200] test loss: 20.509886\n",
      "Epoch [26 / 1200] average loss: 20.105035\n",
      "Epoch [26 / 1200] test loss: 20.640633\n",
      "Epoch [27 / 1200] average loss: 20.017473\n",
      "Epoch [27 / 1200] test loss: 20.351777\n",
      "Epoch [28 / 1200] average loss: 19.881308\n",
      "Epoch [28 / 1200] test loss: 20.484659\n",
      "Epoch [29 / 1200] average loss: 20.152271\n",
      "Epoch [29 / 1200] test loss: 20.324178\n",
      "Epoch [30 / 1200] average loss: 19.962090\n",
      "Epoch [30 / 1200] test loss: 20.193778\n",
      "Epoch [31 / 1200] average loss: 19.846606\n",
      "Epoch [31 / 1200] test loss: 19.674485\n",
      "Epoch [32 / 1200] average loss: 20.081639\n",
      "Epoch [32 / 1200] test loss: 19.644213\n",
      "Epoch [33 / 1200] average loss: 19.693379\n",
      "Epoch [33 / 1200] test loss: 19.772847\n",
      "Epoch [34 / 1200] average loss: 19.510229\n",
      "Epoch [34 / 1200] test loss: 19.722586\n",
      "Epoch [35 / 1200] average loss: 19.746741\n",
      "Epoch [35 / 1200] test loss: 19.595079\n",
      "Epoch [36 / 1200] average loss: 19.389738\n",
      "Epoch [36 / 1200] test loss: 19.638384\n",
      "Epoch [37 / 1200] average loss: 19.467614\n",
      "Epoch [37 / 1200] test loss: 19.788450\n",
      "Epoch [38 / 1200] average loss: 19.311304\n",
      "Epoch [38 / 1200] test loss: 19.542186\n",
      "Epoch [39 / 1200] average loss: 19.488564\n",
      "Epoch [39 / 1200] test loss: 19.524770\n",
      "Epoch [40 / 1200] average loss: 19.337945\n",
      "Epoch [40 / 1200] test loss: 19.489552\n",
      "Epoch [41 / 1200] average loss: 19.285588\n",
      "Epoch [41 / 1200] test loss: 19.414825\n",
      "Epoch [42 / 1200] average loss: 19.266852\n",
      "Epoch [42 / 1200] test loss: 19.388780\n",
      "Epoch [43 / 1200] average loss: 19.014950\n",
      "Epoch [43 / 1200] test loss: 19.097287\n",
      "Epoch [44 / 1200] average loss: 19.117689\n",
      "Epoch [44 / 1200] test loss: 19.165148\n",
      "Epoch [45 / 1200] average loss: 19.175217\n",
      "Epoch [45 / 1200] test loss: 19.263549\n",
      "Epoch [46 / 1200] average loss: 18.893651\n",
      "Epoch [46 / 1200] test loss: 19.069534\n",
      "Epoch [47 / 1200] average loss: 18.926100\n",
      "Epoch [47 / 1200] test loss: 18.964699\n",
      "Epoch [48 / 1200] average loss: 18.973271\n",
      "Epoch [48 / 1200] test loss: 19.016393\n",
      "Epoch [49 / 1200] average loss: 18.741714\n",
      "Epoch [49 / 1200] test loss: 19.077118\n",
      "Epoch [50 / 1200] average loss: 18.699242\n",
      "Epoch [50 / 1200] test loss: 18.948800\n",
      "Epoch [51 / 1200] average loss: 18.920059\n",
      "Epoch [51 / 1200] test loss: 18.827144\n",
      "Epoch [52 / 1200] average loss: 18.689346\n",
      "Epoch [52 / 1200] test loss: 18.633302\n",
      "Epoch [53 / 1200] average loss: 18.676449\n",
      "Epoch [53 / 1200] test loss: 18.487286\n",
      "Epoch [54 / 1200] average loss: 18.585817\n",
      "Epoch [54 / 1200] test loss: 18.616852\n",
      "Epoch [55 / 1200] average loss: 18.602788\n",
      "Epoch [55 / 1200] test loss: 18.762270\n",
      "Epoch [56 / 1200] average loss: 18.437334\n",
      "Epoch [56 / 1200] test loss: 18.607705\n",
      "Epoch [57 / 1200] average loss: 18.530038\n",
      "Epoch [57 / 1200] test loss: 18.549252\n",
      "Epoch [58 / 1200] average loss: 18.312965\n",
      "Epoch [58 / 1200] test loss: 18.493844\n",
      "Epoch [59 / 1200] average loss: 18.333554\n",
      "Epoch [59 / 1200] test loss: 18.758556\n",
      "Epoch [60 / 1200] average loss: 18.375061\n",
      "Epoch [60 / 1200] test loss: 18.149814\n",
      "Epoch [61 / 1200] average loss: 18.305901\n",
      "Epoch [61 / 1200] test loss: 18.374553\n",
      "Epoch [62 / 1200] average loss: 18.303479\n",
      "Epoch [62 / 1200] test loss: 18.298103\n",
      "Epoch [63 / 1200] average loss: 18.108945\n",
      "Epoch [63 / 1200] test loss: 18.177990\n",
      "Epoch [64 / 1200] average loss: 18.201112\n",
      "Epoch [64 / 1200] test loss: 18.363193\n",
      "Epoch [65 / 1200] average loss: 18.016230\n",
      "Epoch [65 / 1200] test loss: 18.016930\n",
      "Epoch [66 / 1200] average loss: 18.100225\n",
      "Epoch [66 / 1200] test loss: 18.177281\n",
      "Epoch [67 / 1200] average loss: 17.972982\n",
      "Epoch [67 / 1200] test loss: 18.173308\n",
      "Epoch [68 / 1200] average loss: 18.075549\n",
      "Epoch [68 / 1200] test loss: 17.977849\n",
      "Epoch [69 / 1200] average loss: 17.965262\n",
      "Epoch [69 / 1200] test loss: 17.974689\n",
      "Epoch [70 / 1200] average loss: 17.856691\n",
      "Epoch [70 / 1200] test loss: 18.111487\n",
      "Epoch [71 / 1200] average loss: 17.912603\n",
      "Epoch [71 / 1200] test loss: 17.993358\n",
      "Epoch [72 / 1200] average loss: 17.811478\n",
      "Epoch [72 / 1200] test loss: 18.029615\n",
      "Epoch [73 / 1200] average loss: 17.748000\n",
      "Epoch [73 / 1200] test loss: 17.839888\n",
      "Epoch [74 / 1200] average loss: 17.745552\n",
      "Epoch [74 / 1200] test loss: 17.956833\n",
      "Epoch [75 / 1200] average loss: 17.728427\n",
      "Epoch [75 / 1200] test loss: 17.820262\n",
      "Epoch [76 / 1200] average loss: 17.644240\n",
      "Epoch [76 / 1200] test loss: 17.714505\n",
      "Epoch [77 / 1200] average loss: 17.528944\n",
      "Epoch [77 / 1200] test loss: 17.900036\n",
      "Epoch [78 / 1200] average loss: 17.452979\n",
      "Epoch [78 / 1200] test loss: 17.444733\n",
      "Epoch [79 / 1200] average loss: 17.500035\n",
      "Epoch [79 / 1200] test loss: 17.485521\n",
      "Epoch [80 / 1200] average loss: 17.365049\n",
      "Epoch [80 / 1200] test loss: 17.498028\n",
      "Epoch [81 / 1200] average loss: 17.571232\n",
      "Epoch [81 / 1200] test loss: 17.507909\n",
      "Epoch [82 / 1200] average loss: 17.329763\n",
      "Epoch [82 / 1200] test loss: 17.340412\n",
      "Epoch [83 / 1200] average loss: 17.364553\n",
      "Epoch [83 / 1200] test loss: 17.266608\n",
      "Epoch [84 / 1200] average loss: 17.260097\n",
      "Epoch [84 / 1200] test loss: 17.358443\n",
      "Epoch [85 / 1200] average loss: 17.243070\n",
      "Epoch [85 / 1200] test loss: 17.399615\n",
      "Epoch [86 / 1200] average loss: 17.192635\n",
      "Epoch [86 / 1200] test loss: 17.377277\n",
      "Epoch [87 / 1200] average loss: 17.109000\n",
      "Epoch [87 / 1200] test loss: 17.227362\n",
      "Epoch [88 / 1200] average loss: 17.090464\n",
      "Epoch [88 / 1200] test loss: 17.012772\n",
      "Epoch [89 / 1200] average loss: 17.065709\n",
      "Epoch [89 / 1200] test loss: 17.055334\n",
      "Epoch [90 / 1200] average loss: 16.957955\n",
      "Epoch [90 / 1200] test loss: 17.054444\n",
      "Epoch [91 / 1200] average loss: 16.867645\n",
      "Epoch [91 / 1200] test loss: 17.078994\n",
      "Epoch [92 / 1200] average loss: 16.967498\n",
      "Epoch [92 / 1200] test loss: 16.948379\n",
      "Epoch [93 / 1200] average loss: 16.830604\n",
      "Epoch [93 / 1200] test loss: 16.836599\n",
      "Epoch [94 / 1200] average loss: 16.882513\n",
      "Epoch [94 / 1200] test loss: 17.061593\n",
      "Epoch [95 / 1200] average loss: 16.746003\n",
      "Epoch [95 / 1200] test loss: 16.829835\n",
      "Epoch [96 / 1200] average loss: 16.805163\n",
      "Epoch [96 / 1200] test loss: 16.748697\n",
      "Epoch [97 / 1200] average loss: 16.614418\n",
      "Epoch [97 / 1200] test loss: 16.593215\n",
      "Epoch [98 / 1200] average loss: 16.663092\n",
      "Epoch [98 / 1200] test loss: 16.750311\n",
      "Epoch [99 / 1200] average loss: 16.586569\n",
      "Epoch [99 / 1200] test loss: 16.529468\n",
      "Epoch [100 / 1200] average loss: 16.802973\n",
      "Epoch [100 / 1200] test loss: 16.524205\n",
      "Epoch [101 / 1200] average loss: 16.435983\n",
      "Epoch [101 / 1200] test loss: 16.384680\n",
      "Epoch [102 / 1200] average loss: 16.476417\n",
      "Epoch [102 / 1200] test loss: 16.291146\n",
      "Epoch [103 / 1200] average loss: 16.544934\n",
      "Epoch [103 / 1200] test loss: 16.332367\n",
      "Epoch [104 / 1200] average loss: 16.414096\n",
      "Epoch [104 / 1200] test loss: 16.230372\n",
      "Epoch [105 / 1200] average loss: 16.323788\n",
      "Epoch [105 / 1200] test loss: 16.133516\n",
      "Epoch [106 / 1200] average loss: 16.190240\n",
      "Epoch [106 / 1200] test loss: 16.175346\n",
      "Epoch [107 / 1200] average loss: 16.298780\n",
      "Epoch [107 / 1200] test loss: 16.038584\n",
      "Epoch [108 / 1200] average loss: 16.431821\n",
      "Epoch [108 / 1200] test loss: 15.820918\n",
      "Epoch [109 / 1200] average loss: 16.046342\n",
      "Epoch [109 / 1200] test loss: 16.088640\n",
      "Epoch [110 / 1200] average loss: 16.014877\n",
      "Epoch [110 / 1200] test loss: 16.061163\n",
      "Epoch [111 / 1200] average loss: 15.989363\n",
      "Epoch [111 / 1200] test loss: 15.851156\n",
      "Epoch [112 / 1200] average loss: 15.910479\n",
      "Epoch [112 / 1200] test loss: 15.763716\n",
      "Epoch [113 / 1200] average loss: 15.844912\n",
      "Epoch [113 / 1200] test loss: 15.799000\n",
      "Epoch [114 / 1200] average loss: 15.952948\n",
      "Epoch [114 / 1200] test loss: 15.753898\n",
      "Epoch [115 / 1200] average loss: 15.780200\n",
      "Epoch [115 / 1200] test loss: 15.704410\n",
      "Epoch [116 / 1200] average loss: 15.769909\n",
      "Epoch [116 / 1200] test loss: 15.576069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117 / 1200] average loss: 15.692344\n",
      "Epoch [117 / 1200] test loss: 15.561749\n",
      "Epoch [118 / 1200] average loss: 15.689857\n",
      "Epoch [118 / 1200] test loss: 15.392739\n",
      "Epoch [119 / 1200] average loss: 15.805028\n",
      "Epoch [119 / 1200] test loss: 15.319826\n",
      "Epoch [120 / 1200] average loss: 15.543480\n",
      "Epoch [120 / 1200] test loss: 15.561153\n",
      "Epoch [121 / 1200] average loss: 15.515258\n",
      "Epoch [121 / 1200] test loss: 15.329897\n",
      "Epoch [122 / 1200] average loss: 15.577035\n",
      "Epoch [122 / 1200] test loss: 15.268229\n",
      "Epoch [123 / 1200] average loss: 15.616672\n",
      "Epoch [123 / 1200] test loss: 15.205450\n",
      "Epoch [124 / 1200] average loss: 15.363191\n",
      "Epoch [124 / 1200] test loss: 15.192124\n",
      "Epoch [125 / 1200] average loss: 15.426717\n",
      "Epoch [125 / 1200] test loss: 15.140734\n",
      "Epoch [126 / 1200] average loss: 15.386532\n",
      "Epoch [126 / 1200] test loss: 15.035402\n",
      "Epoch [127 / 1200] average loss: 15.226015\n",
      "Epoch [127 / 1200] test loss: 15.171616\n",
      "Epoch [128 / 1200] average loss: 15.252707\n",
      "Epoch [128 / 1200] test loss: 14.869942\n",
      "Epoch [129 / 1200] average loss: 15.216093\n",
      "Epoch [129 / 1200] test loss: 14.863692\n",
      "Epoch [130 / 1200] average loss: 15.019019\n",
      "Epoch [130 / 1200] test loss: 14.862255\n",
      "Epoch [131 / 1200] average loss: 14.971458\n",
      "Epoch [131 / 1200] test loss: 14.858856\n",
      "Epoch [132 / 1200] average loss: 14.929223\n",
      "Epoch [132 / 1200] test loss: 14.803016\n",
      "Epoch [133 / 1200] average loss: 15.027880\n",
      "Epoch [133 / 1200] test loss: 14.748336\n",
      "Epoch [134 / 1200] average loss: 14.933214\n",
      "Epoch [134 / 1200] test loss: 14.668975\n",
      "Epoch [135 / 1200] average loss: 15.037777\n",
      "Epoch [135 / 1200] test loss: 14.696158\n",
      "Epoch [136 / 1200] average loss: 14.840367\n",
      "Epoch [136 / 1200] test loss: 14.519731\n",
      "Epoch [137 / 1200] average loss: 14.831935\n",
      "Epoch [137 / 1200] test loss: 14.396544\n",
      "Epoch [138 / 1200] average loss: 14.686697\n",
      "Epoch [138 / 1200] test loss: 14.637951\n",
      "Epoch [139 / 1200] average loss: 14.572794\n",
      "Epoch [139 / 1200] test loss: 14.487170\n",
      "Epoch [140 / 1200] average loss: 14.699652\n",
      "Epoch [140 / 1200] test loss: 14.250789\n",
      "Epoch [141 / 1200] average loss: 14.597354\n",
      "Epoch [141 / 1200] test loss: 14.299386\n",
      "Epoch [142 / 1200] average loss: 14.561235\n",
      "Epoch [142 / 1200] test loss: 14.257800\n",
      "Epoch [143 / 1200] average loss: 14.501518\n",
      "Epoch [143 / 1200] test loss: 14.183878\n",
      "Epoch [144 / 1200] average loss: 14.414005\n",
      "Epoch [144 / 1200] test loss: 14.062902\n",
      "Epoch [145 / 1200] average loss: 14.346557\n",
      "Epoch [145 / 1200] test loss: 14.034807\n",
      "Epoch [146 / 1200] average loss: 14.327478\n",
      "Epoch [146 / 1200] test loss: 13.978267\n",
      "Epoch [147 / 1200] average loss: 14.273228\n",
      "Epoch [147 / 1200] test loss: 13.991346\n",
      "Epoch [148 / 1200] average loss: 14.155994\n",
      "Epoch [148 / 1200] test loss: 14.104616\n",
      "Epoch [149 / 1200] average loss: 14.354771\n",
      "Epoch [149 / 1200] test loss: 13.889865\n",
      "Epoch [150 / 1200] average loss: 14.113577\n",
      "Epoch [150 / 1200] test loss: 13.786146\n",
      "Epoch [151 / 1200] average loss: 14.194400\n",
      "Epoch [151 / 1200] test loss: 13.831406\n",
      "Epoch [152 / 1200] average loss: 13.998451\n",
      "Epoch [152 / 1200] test loss: 13.642596\n",
      "Epoch [153 / 1200] average loss: 14.010266\n",
      "Epoch [153 / 1200] test loss: 13.579704\n",
      "Epoch [154 / 1200] average loss: 13.921426\n",
      "Epoch [154 / 1200] test loss: 13.630865\n",
      "Epoch [155 / 1200] average loss: 14.014053\n",
      "Epoch [155 / 1200] test loss: 13.586983\n",
      "Epoch [156 / 1200] average loss: 13.805841\n",
      "Epoch [156 / 1200] test loss: 13.382285\n",
      "Epoch [157 / 1200] average loss: 13.713713\n",
      "Epoch [157 / 1200] test loss: 13.606383\n",
      "Epoch [158 / 1200] average loss: 13.804438\n",
      "Epoch [158 / 1200] test loss: 13.478699\n",
      "Epoch [159 / 1200] average loss: 13.760575\n",
      "Epoch [159 / 1200] test loss: 13.472214\n",
      "Epoch [160 / 1200] average loss: 13.654133\n",
      "Epoch [160 / 1200] test loss: 13.366793\n",
      "Epoch [161 / 1200] average loss: 13.498753\n",
      "Epoch [161 / 1200] test loss: 13.263616\n",
      "Epoch [162 / 1200] average loss: 13.579727\n",
      "Epoch [162 / 1200] test loss: 13.130056\n",
      "Epoch [163 / 1200] average loss: 13.699712\n",
      "Epoch [163 / 1200] test loss: 13.330007\n",
      "Epoch [164 / 1200] average loss: 13.640021\n",
      "Epoch [164 / 1200] test loss: 13.228575\n",
      "Epoch [165 / 1200] average loss: 13.537536\n",
      "Epoch [165 / 1200] test loss: 13.097978\n",
      "Epoch [166 / 1200] average loss: 13.518082\n",
      "Epoch [166 / 1200] test loss: 12.938859\n",
      "Epoch [167 / 1200] average loss: 13.443560\n",
      "Epoch [167 / 1200] test loss: 13.056305\n",
      "Epoch [168 / 1200] average loss: 13.344761\n",
      "Epoch [168 / 1200] test loss: 12.936002\n",
      "Epoch [169 / 1200] average loss: 13.444291\n",
      "Epoch [169 / 1200] test loss: 13.213391\n",
      "Epoch [170 / 1200] average loss: 13.388300\n",
      "Epoch [170 / 1200] test loss: 13.201254\n",
      "Epoch [171 / 1200] average loss: 13.142995\n",
      "Epoch [171 / 1200] test loss: 12.812255\n",
      "Epoch [172 / 1200] average loss: 13.208360\n",
      "Epoch [172 / 1200] test loss: 12.744358\n",
      "Epoch [173 / 1200] average loss: 13.149633\n",
      "Epoch [173 / 1200] test loss: 12.974626\n",
      "Epoch [174 / 1200] average loss: 13.103564\n",
      "Epoch [174 / 1200] test loss: 12.737415\n",
      "Epoch [175 / 1200] average loss: 13.101976\n",
      "Epoch [175 / 1200] test loss: 12.696313\n",
      "Epoch [176 / 1200] average loss: 13.007893\n",
      "Epoch [176 / 1200] test loss: 12.633282\n",
      "Epoch [177 / 1200] average loss: 12.995366\n",
      "Epoch [177 / 1200] test loss: 12.587471\n",
      "Epoch [178 / 1200] average loss: 12.967171\n",
      "Epoch [178 / 1200] test loss: 12.983117\n",
      "Epoch [179 / 1200] average loss: 12.986786\n",
      "Epoch [179 / 1200] test loss: 12.491989\n",
      "Epoch [180 / 1200] average loss: 12.787212\n",
      "Epoch [180 / 1200] test loss: 12.557641\n",
      "Epoch [181 / 1200] average loss: 12.863708\n",
      "Epoch [181 / 1200] test loss: 12.444052\n",
      "Epoch [182 / 1200] average loss: 12.939122\n",
      "Epoch [182 / 1200] test loss: 12.504615\n",
      "Epoch [183 / 1200] average loss: 12.865134\n",
      "Epoch [183 / 1200] test loss: 12.528692\n",
      "Epoch [184 / 1200] average loss: 12.767782\n",
      "Epoch [184 / 1200] test loss: 12.385398\n",
      "Epoch [185 / 1200] average loss: 12.772883\n",
      "Epoch [185 / 1200] test loss: 12.230553\n",
      "Epoch [186 / 1200] average loss: 12.718428\n",
      "Epoch [186 / 1200] test loss: 12.211596\n",
      "Epoch [187 / 1200] average loss: 12.593768\n",
      "Epoch [187 / 1200] test loss: 12.267118\n",
      "Epoch [188 / 1200] average loss: 12.675129\n",
      "Epoch [188 / 1200] test loss: 12.211524\n",
      "Epoch [189 / 1200] average loss: 12.525727\n",
      "Epoch [189 / 1200] test loss: 12.323016\n",
      "Epoch [190 / 1200] average loss: 12.521425\n",
      "Epoch [190 / 1200] test loss: 12.069610\n",
      "Epoch [191 / 1200] average loss: 12.716129\n",
      "Epoch [191 / 1200] test loss: 12.240508\n",
      "Epoch [192 / 1200] average loss: 12.502276\n",
      "Epoch [192 / 1200] test loss: 12.105122\n",
      "Epoch [193 / 1200] average loss: 12.413760\n",
      "Epoch [193 / 1200] test loss: 12.062439\n",
      "Epoch [194 / 1200] average loss: 12.797115\n",
      "Epoch [194 / 1200] test loss: 12.077461\n",
      "Epoch [195 / 1200] average loss: 12.465383\n",
      "Epoch [195 / 1200] test loss: 11.952472\n",
      "Epoch [196 / 1200] average loss: 12.540443\n",
      "Epoch [196 / 1200] test loss: 11.935381\n",
      "Epoch [197 / 1200] average loss: 12.489670\n",
      "Epoch [197 / 1200] test loss: 12.028061\n",
      "Epoch [198 / 1200] average loss: 12.468516\n",
      "Epoch [198 / 1200] test loss: 11.978635\n",
      "Epoch [199 / 1200] average loss: 12.412967\n",
      "Epoch [199 / 1200] test loss: 12.009690\n",
      "Epoch [200 / 1200] average loss: 12.290732\n",
      "Epoch [200 / 1200] test loss: 11.975022\n",
      "Epoch [201 / 1200] average loss: 12.456608\n",
      "Epoch [201 / 1200] test loss: 11.821563\n",
      "Epoch [202 / 1200] average loss: 12.296656\n",
      "Epoch [202 / 1200] test loss: 11.854579\n",
      "Epoch [203 / 1200] average loss: 12.214324\n",
      "Epoch [203 / 1200] test loss: 11.776553\n",
      "Epoch [204 / 1200] average loss: 12.421553\n",
      "Epoch [204 / 1200] test loss: 11.915229\n",
      "Epoch [205 / 1200] average loss: 12.135234\n",
      "Epoch [205 / 1200] test loss: 11.709480\n",
      "Epoch [206 / 1200] average loss: 12.076326\n",
      "Epoch [206 / 1200] test loss: 11.729923\n",
      "Epoch [207 / 1200] average loss: 12.218758\n",
      "Epoch [207 / 1200] test loss: 11.890887\n",
      "Epoch [208 / 1200] average loss: 12.112744\n",
      "Epoch [208 / 1200] test loss: 11.750742\n",
      "Epoch [209 / 1200] average loss: 12.202514\n",
      "Epoch [209 / 1200] test loss: 12.016968\n",
      "Epoch [210 / 1200] average loss: 12.070022\n",
      "Epoch [210 / 1200] test loss: 11.616476\n",
      "Epoch [211 / 1200] average loss: 12.075948\n",
      "Epoch [211 / 1200] test loss: 11.660087\n",
      "Epoch [212 / 1200] average loss: 11.965266\n",
      "Epoch [212 / 1200] test loss: 11.454909\n",
      "Epoch [213 / 1200] average loss: 12.075914\n",
      "Epoch [213 / 1200] test loss: 11.427461\n",
      "Epoch [214 / 1200] average loss: 11.915281\n",
      "Epoch [214 / 1200] test loss: 11.609418\n",
      "Epoch [215 / 1200] average loss: 11.903636\n",
      "Epoch [215 / 1200] test loss: 11.627756\n",
      "Epoch [216 / 1200] average loss: 11.909991\n",
      "Epoch [216 / 1200] test loss: 11.398273\n",
      "Epoch [217 / 1200] average loss: 11.806053\n",
      "Epoch [217 / 1200] test loss: 11.465384\n",
      "Epoch [218 / 1200] average loss: 11.924313\n",
      "Epoch [218 / 1200] test loss: 11.410409\n",
      "Epoch [219 / 1200] average loss: 11.798860\n",
      "Epoch [219 / 1200] test loss: 11.279951\n",
      "Epoch [220 / 1200] average loss: 11.826705\n",
      "Epoch [220 / 1200] test loss: 11.589932\n",
      "Epoch [221 / 1200] average loss: 11.941057\n",
      "Epoch [221 / 1200] test loss: 11.365037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [222 / 1200] average loss: 11.678703\n",
      "Epoch [222 / 1200] test loss: 11.374511\n",
      "Epoch [223 / 1200] average loss: 11.673032\n",
      "Epoch [223 / 1200] test loss: 11.404939\n",
      "Epoch [224 / 1200] average loss: 11.724422\n",
      "Epoch [224 / 1200] test loss: 11.372659\n",
      "Epoch [225 / 1200] average loss: 11.685221\n",
      "Epoch [225 / 1200] test loss: 11.392373\n",
      "Epoch [226 / 1200] average loss: 11.683221\n",
      "Epoch [226 / 1200] test loss: 11.099400\n",
      "Epoch [227 / 1200] average loss: 11.613379\n",
      "Epoch [227 / 1200] test loss: 11.182698\n",
      "Epoch [228 / 1200] average loss: 11.590575\n",
      "Epoch [228 / 1200] test loss: 11.260294\n",
      "Epoch [229 / 1200] average loss: 11.641959\n",
      "Epoch [229 / 1200] test loss: 11.415808\n",
      "Epoch [230 / 1200] average loss: 11.487217\n",
      "Epoch [230 / 1200] test loss: 11.261675\n",
      "Epoch [231 / 1200] average loss: 11.534282\n",
      "Epoch [231 / 1200] test loss: 10.990989\n",
      "Epoch [232 / 1200] average loss: 11.475633\n",
      "Epoch [232 / 1200] test loss: 11.310275\n",
      "Epoch [233 / 1200] average loss: 11.462975\n",
      "Epoch [233 / 1200] test loss: 11.105547\n",
      "Epoch [234 / 1200] average loss: 11.548629\n",
      "Epoch [234 / 1200] test loss: 11.080899\n",
      "Epoch [235 / 1200] average loss: 11.446306\n",
      "Epoch [235 / 1200] test loss: 10.995943\n",
      "Epoch [236 / 1200] average loss: 11.441657\n",
      "Epoch [236 / 1200] test loss: 11.012442\n",
      "Epoch [237 / 1200] average loss: 11.372142\n",
      "Epoch [237 / 1200] test loss: 10.915565\n",
      "Epoch [238 / 1200] average loss: 11.401667\n",
      "Epoch [238 / 1200] test loss: 10.970999\n",
      "Epoch [239 / 1200] average loss: 11.420316\n",
      "Epoch [239 / 1200] test loss: 11.075606\n",
      "Epoch [240 / 1200] average loss: 11.317760\n",
      "Epoch [240 / 1200] test loss: 10.836426\n",
      "Epoch [241 / 1200] average loss: 11.240312\n",
      "Epoch [241 / 1200] test loss: 10.964716\n",
      "Epoch [242 / 1200] average loss: 11.326164\n",
      "Epoch [242 / 1200] test loss: 10.855760\n",
      "Epoch [243 / 1200] average loss: 11.284881\n",
      "Epoch [243 / 1200] test loss: 10.879599\n",
      "Epoch [244 / 1200] average loss: 11.297381\n",
      "Epoch [244 / 1200] test loss: 11.815294\n",
      "Epoch [245 / 1200] average loss: 11.232843\n",
      "Epoch [245 / 1200] test loss: 10.776458\n",
      "Epoch [246 / 1200] average loss: 11.237514\n",
      "Epoch [246 / 1200] test loss: 10.658874\n",
      "Epoch [247 / 1200] average loss: 11.186419\n",
      "Epoch [247 / 1200] test loss: 10.743145\n",
      "Epoch [248 / 1200] average loss: 11.151385\n",
      "Epoch [248 / 1200] test loss: 10.643475\n",
      "Epoch [249 / 1200] average loss: 11.347688\n",
      "Epoch [249 / 1200] test loss: 10.738706\n",
      "Epoch [250 / 1200] average loss: 11.135825\n",
      "Epoch [250 / 1200] test loss: 10.660833\n",
      "Epoch [251 / 1200] average loss: 11.033669\n",
      "Epoch [251 / 1200] test loss: 10.665748\n",
      "Epoch [252 / 1200] average loss: 10.906029\n",
      "Epoch [252 / 1200] test loss: 10.673616\n",
      "Epoch [253 / 1200] average loss: 10.966488\n",
      "Epoch [253 / 1200] test loss: 10.636852\n",
      "Epoch [254 / 1200] average loss: 10.918843\n",
      "Epoch [254 / 1200] test loss: 10.875846\n",
      "Epoch [255 / 1200] average loss: 10.875326\n",
      "Epoch [255 / 1200] test loss: 10.678919\n",
      "Epoch [256 / 1200] average loss: 10.914823\n",
      "Epoch [256 / 1200] test loss: 10.629544\n",
      "Epoch [257 / 1200] average loss: 10.890126\n",
      "Epoch [257 / 1200] test loss: 10.394265\n",
      "Epoch [258 / 1200] average loss: 10.882803\n",
      "Epoch [258 / 1200] test loss: 10.475924\n",
      "Epoch [259 / 1200] average loss: 10.913001\n",
      "Epoch [259 / 1200] test loss: 10.569062\n",
      "Epoch [260 / 1200] average loss: 10.931268\n",
      "Epoch [260 / 1200] test loss: 10.630000\n",
      "Epoch [261 / 1200] average loss: 10.870039\n",
      "Epoch [261 / 1200] test loss: 10.525576\n",
      "Epoch [262 / 1200] average loss: 10.740926\n",
      "Epoch [262 / 1200] test loss: 10.509218\n",
      "Epoch [263 / 1200] average loss: 10.751110\n",
      "Epoch [263 / 1200] test loss: 10.366171\n",
      "Epoch [264 / 1200] average loss: 10.893418\n",
      "Epoch [264 / 1200] test loss: 10.200237\n",
      "Epoch [265 / 1200] average loss: 10.697946\n",
      "Epoch [265 / 1200] test loss: 10.347991\n",
      "Epoch [266 / 1200] average loss: 10.637632\n",
      "Epoch [266 / 1200] test loss: 10.270580\n",
      "Epoch [267 / 1200] average loss: 10.865083\n",
      "Epoch [267 / 1200] test loss: 10.494086\n",
      "Epoch [268 / 1200] average loss: 10.751201\n",
      "Epoch [268 / 1200] test loss: 10.231329\n",
      "Epoch [269 / 1200] average loss: 10.599565\n",
      "Epoch [269 / 1200] test loss: 10.225222\n",
      "Epoch [270 / 1200] average loss: 10.605554\n",
      "Epoch [270 / 1200] test loss: 10.306956\n",
      "Epoch [271 / 1200] average loss: 10.712819\n",
      "Epoch [271 / 1200] test loss: 10.261108\n",
      "Epoch [272 / 1200] average loss: 10.597695\n",
      "Epoch [272 / 1200] test loss: 10.234669\n",
      "Epoch [273 / 1200] average loss: 10.592523\n",
      "Epoch [273 / 1200] test loss: 10.078176\n",
      "Epoch [274 / 1200] average loss: 10.556237\n",
      "Epoch [274 / 1200] test loss: 10.342958\n",
      "Epoch [275 / 1200] average loss: 10.665355\n",
      "Epoch [275 / 1200] test loss: 10.062678\n",
      "Epoch [276 / 1200] average loss: 10.503405\n",
      "Epoch [276 / 1200] test loss: 10.107208\n",
      "Epoch [277 / 1200] average loss: 10.409212\n",
      "Epoch [277 / 1200] test loss: 10.011902\n",
      "Epoch [278 / 1200] average loss: 10.608508\n",
      "Epoch [278 / 1200] test loss: 10.459516\n",
      "Epoch [279 / 1200] average loss: 10.556821\n",
      "Epoch [279 / 1200] test loss: 10.167498\n",
      "Epoch [280 / 1200] average loss: 10.448970\n",
      "Epoch [280 / 1200] test loss: 9.947025\n",
      "Epoch [281 / 1200] average loss: 10.489415\n",
      "Epoch [281 / 1200] test loss: 10.036317\n",
      "Epoch [282 / 1200] average loss: 10.394335\n",
      "Epoch [282 / 1200] test loss: 9.963638\n",
      "Epoch [283 / 1200] average loss: 10.458840\n",
      "Epoch [283 / 1200] test loss: 9.830068\n",
      "Epoch [284 / 1200] average loss: 10.429521\n",
      "Epoch [284 / 1200] test loss: 9.977823\n",
      "Epoch [285 / 1200] average loss: 10.309798\n",
      "Epoch [285 / 1200] test loss: 9.962713\n",
      "Epoch [286 / 1200] average loss: 10.358131\n",
      "Epoch [286 / 1200] test loss: 9.800222\n",
      "Epoch [287 / 1200] average loss: 10.287320\n",
      "Epoch [287 / 1200] test loss: 9.947394\n",
      "Epoch [288 / 1200] average loss: 10.690916\n",
      "Epoch [288 / 1200] test loss: 9.934955\n",
      "Epoch [289 / 1200] average loss: 10.234284\n",
      "Epoch [289 / 1200] test loss: 9.908165\n",
      "Epoch [290 / 1200] average loss: 10.387555\n",
      "Epoch [290 / 1200] test loss: 9.738042\n",
      "Epoch [291 / 1200] average loss: 10.139921\n",
      "Epoch [291 / 1200] test loss: 9.800622\n",
      "Epoch [292 / 1200] average loss: 10.223333\n",
      "Epoch [292 / 1200] test loss: 9.758282\n",
      "Epoch [293 / 1200] average loss: 10.283667\n",
      "Epoch [293 / 1200] test loss: 9.872661\n",
      "Epoch [294 / 1200] average loss: 10.232319\n",
      "Epoch [294 / 1200] test loss: 9.825598\n",
      "Epoch [295 / 1200] average loss: 10.179252\n",
      "Epoch [295 / 1200] test loss: 9.543485\n",
      "Epoch [296 / 1200] average loss: 10.032682\n",
      "Epoch [296 / 1200] test loss: 9.727559\n",
      "Epoch [297 / 1200] average loss: 9.985331\n",
      "Epoch [297 / 1200] test loss: 9.939052\n",
      "Epoch [298 / 1200] average loss: 10.123550\n",
      "Epoch [298 / 1200] test loss: 9.581130\n",
      "Epoch [299 / 1200] average loss: 10.113953\n",
      "Epoch [299 / 1200] test loss: 9.700977\n",
      "Epoch [300 / 1200] average loss: 10.294960\n",
      "Epoch [300 / 1200] test loss: 9.792275\n",
      "Epoch [301 / 1200] average loss: 10.082848\n",
      "Epoch [301 / 1200] test loss: 9.619732\n",
      "Epoch [302 / 1200] average loss: 10.197188\n",
      "Epoch [302 / 1200] test loss: 9.603157\n",
      "Epoch [303 / 1200] average loss: 10.283940\n",
      "Epoch [303 / 1200] test loss: 9.594610\n",
      "Epoch [304 / 1200] average loss: 10.152088\n",
      "Epoch [304 / 1200] test loss: 9.555589\n",
      "Epoch [305 / 1200] average loss: 9.994387\n",
      "Epoch [305 / 1200] test loss: 9.643569\n",
      "Epoch [306 / 1200] average loss: 10.006183\n",
      "Epoch [306 / 1200] test loss: 9.637695\n",
      "Epoch [307 / 1200] average loss: 10.005927\n",
      "Epoch [307 / 1200] test loss: 9.628677\n",
      "Epoch [308 / 1200] average loss: 9.957330\n",
      "Epoch [308 / 1200] test loss: 9.568281\n",
      "Epoch [309 / 1200] average loss: 10.000962\n",
      "Epoch [309 / 1200] test loss: 9.576491\n",
      "Epoch [310 / 1200] average loss: 9.915782\n",
      "Epoch [310 / 1200] test loss: 9.530393\n",
      "Epoch [311 / 1200] average loss: 9.994906\n",
      "Epoch [311 / 1200] test loss: 9.464567\n",
      "Epoch [312 / 1200] average loss: 9.832825\n",
      "Epoch [312 / 1200] test loss: 9.489102\n",
      "Epoch [313 / 1200] average loss: 9.919621\n",
      "Epoch [313 / 1200] test loss: 9.455207\n",
      "Epoch [314 / 1200] average loss: 9.794428\n",
      "Epoch [314 / 1200] test loss: 9.479462\n",
      "Epoch [315 / 1200] average loss: 9.836545\n",
      "Epoch [315 / 1200] test loss: 9.377244\n",
      "Epoch [316 / 1200] average loss: 9.933392\n",
      "Epoch [316 / 1200] test loss: 9.372255\n",
      "Epoch [317 / 1200] average loss: 9.920110\n",
      "Epoch [317 / 1200] test loss: 9.523208\n",
      "Epoch [318 / 1200] average loss: 9.907256\n",
      "Epoch [318 / 1200] test loss: 9.457922\n",
      "Epoch [319 / 1200] average loss: 9.874448\n",
      "Epoch [319 / 1200] test loss: 9.326522\n",
      "Epoch [320 / 1200] average loss: 9.843747\n",
      "Epoch [320 / 1200] test loss: 9.270489\n",
      "Epoch [321 / 1200] average loss: 9.801689\n",
      "Epoch [321 / 1200] test loss: 9.525202\n",
      "Epoch [322 / 1200] average loss: 9.756957\n",
      "Epoch [322 / 1200] test loss: 9.321222\n",
      "Epoch [323 / 1200] average loss: 9.734059\n",
      "Epoch [323 / 1200] test loss: 9.276316\n",
      "Epoch [324 / 1200] average loss: 9.721665\n",
      "Epoch [324 / 1200] test loss: 9.368829\n",
      "Epoch [325 / 1200] average loss: 9.702447\n",
      "Epoch [325 / 1200] test loss: 9.490867\n",
      "Epoch [326 / 1200] average loss: 9.848855\n",
      "Epoch [326 / 1200] test loss: 9.382747\n",
      "Epoch [327 / 1200] average loss: 9.731309\n",
      "Epoch [327 / 1200] test loss: 9.182414\n",
      "Epoch [328 / 1200] average loss: 9.731409\n",
      "Epoch [328 / 1200] test loss: 9.347967\n",
      "Epoch [329 / 1200] average loss: 9.850722\n",
      "Epoch [329 / 1200] test loss: 9.267140\n",
      "Epoch [330 / 1200] average loss: 9.973053\n",
      "Epoch [330 / 1200] test loss: 9.271336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [331 / 1200] average loss: 9.854521\n",
      "Epoch [331 / 1200] test loss: 9.267374\n",
      "Epoch [332 / 1200] average loss: 9.741387\n",
      "Epoch [332 / 1200] test loss: 9.335008\n",
      "Epoch [333 / 1200] average loss: 9.625674\n",
      "Epoch [333 / 1200] test loss: 9.313498\n",
      "Epoch [334 / 1200] average loss: 9.718443\n",
      "Epoch [334 / 1200] test loss: 9.217295\n",
      "Epoch [335 / 1200] average loss: 9.663107\n",
      "Epoch [335 / 1200] test loss: 9.317610\n",
      "Epoch [336 / 1200] average loss: 9.496961\n",
      "Epoch [336 / 1200] test loss: 9.173053\n",
      "Epoch [337 / 1200] average loss: 9.545966\n",
      "Epoch [337 / 1200] test loss: 9.183625\n",
      "Epoch [338 / 1200] average loss: 9.484247\n",
      "Epoch [338 / 1200] test loss: 9.149639\n",
      "Epoch [339 / 1200] average loss: 9.549853\n",
      "Epoch [339 / 1200] test loss: 9.256474\n",
      "Epoch [340 / 1200] average loss: 9.534840\n",
      "Epoch [340 / 1200] test loss: 9.085864\n",
      "Epoch [341 / 1200] average loss: 9.509578\n",
      "Epoch [341 / 1200] test loss: 9.209113\n",
      "Epoch [342 / 1200] average loss: 9.461403\n",
      "Epoch [342 / 1200] test loss: 9.186053\n",
      "Epoch [343 / 1200] average loss: 9.478623\n",
      "Epoch [343 / 1200] test loss: 9.111166\n",
      "Epoch [344 / 1200] average loss: 9.433155\n",
      "Epoch [344 / 1200] test loss: 9.215289\n",
      "Epoch [345 / 1200] average loss: 9.450763\n",
      "Epoch [345 / 1200] test loss: 9.008726\n",
      "Epoch [346 / 1200] average loss: 9.360141\n",
      "Epoch [346 / 1200] test loss: 9.106186\n",
      "Epoch [347 / 1200] average loss: 9.484022\n",
      "Epoch [347 / 1200] test loss: 9.083268\n",
      "Epoch [348 / 1200] average loss: 9.478724\n",
      "Epoch [348 / 1200] test loss: 9.104670\n",
      "Epoch [349 / 1200] average loss: 9.364464\n",
      "Epoch [349 / 1200] test loss: 8.962218\n",
      "Epoch [350 / 1200] average loss: 9.294118\n",
      "Epoch [350 / 1200] test loss: 9.002460\n",
      "Epoch [351 / 1200] average loss: 9.327822\n",
      "Epoch [351 / 1200] test loss: 9.006553\n",
      "Epoch [352 / 1200] average loss: 9.508560\n",
      "Epoch [352 / 1200] test loss: 9.131092\n",
      "Epoch [353 / 1200] average loss: 9.482230\n",
      "Epoch [353 / 1200] test loss: 9.244473\n",
      "Epoch [354 / 1200] average loss: 9.388641\n",
      "Epoch [354 / 1200] test loss: 8.933117\n",
      "Epoch [355 / 1200] average loss: 9.589040\n",
      "Epoch [355 / 1200] test loss: 9.101255\n",
      "Epoch [356 / 1200] average loss: 9.398711\n",
      "Epoch [356 / 1200] test loss: 8.736636\n",
      "Epoch [357 / 1200] average loss: 9.344577\n",
      "Epoch [357 / 1200] test loss: 8.967224\n",
      "Epoch [358 / 1200] average loss: 9.341206\n",
      "Epoch [358 / 1200] test loss: 8.901929\n",
      "Epoch [359 / 1200] average loss: 9.360523\n",
      "Epoch [359 / 1200] test loss: 9.215426\n",
      "Epoch [360 / 1200] average loss: 9.438252\n",
      "Epoch [360 / 1200] test loss: 8.729305\n",
      "Epoch [361 / 1200] average loss: 9.487199\n",
      "Epoch [361 / 1200] test loss: 9.228494\n",
      "Epoch [362 / 1200] average loss: 9.607628\n",
      "Epoch [362 / 1200] test loss: 8.826918\n",
      "Epoch [363 / 1200] average loss: 9.461205\n",
      "Epoch [363 / 1200] test loss: 9.183860\n",
      "Epoch [364 / 1200] average loss: 9.417540\n",
      "Epoch [364 / 1200] test loss: 9.294910\n",
      "Epoch [365 / 1200] average loss: 9.355515\n",
      "Epoch [365 / 1200] test loss: 9.263537\n",
      "Epoch [366 / 1200] average loss: 9.460384\n",
      "Epoch [366 / 1200] test loss: 9.147098\n",
      "Epoch [367 / 1200] average loss: 9.230716\n",
      "Epoch [367 / 1200] test loss: 8.962561\n",
      "Epoch [368 / 1200] average loss: 9.250195\n",
      "Epoch [368 / 1200] test loss: 8.734939\n",
      "Epoch [369 / 1200] average loss: 9.184562\n",
      "Epoch [369 / 1200] test loss: 8.824279\n",
      "Epoch [370 / 1200] average loss: 9.143828\n",
      "Epoch [370 / 1200] test loss: 8.823716\n",
      "Epoch [371 / 1200] average loss: 9.178020\n",
      "Epoch [371 / 1200] test loss: 8.648530\n",
      "Epoch [372 / 1200] average loss: 9.257675\n",
      "Epoch [372 / 1200] test loss: 8.715458\n",
      "Epoch [373 / 1200] average loss: 9.039852\n",
      "Epoch [373 / 1200] test loss: 8.764686\n",
      "Epoch [374 / 1200] average loss: 9.169979\n",
      "Epoch [374 / 1200] test loss: 8.985445\n",
      "Epoch [375 / 1200] average loss: 9.096205\n",
      "Epoch [375 / 1200] test loss: 8.746198\n",
      "Epoch [376 / 1200] average loss: 9.062176\n",
      "Epoch [376 / 1200] test loss: 8.684797\n",
      "Epoch [377 / 1200] average loss: 8.953976\n",
      "Epoch [377 / 1200] test loss: 8.831271\n",
      "Epoch [378 / 1200] average loss: 9.035541\n",
      "Epoch [378 / 1200] test loss: 8.607769\n",
      "Epoch [379 / 1200] average loss: 9.058737\n",
      "Epoch [379 / 1200] test loss: 8.676940\n",
      "Epoch [380 / 1200] average loss: 9.023163\n",
      "Epoch [380 / 1200] test loss: 8.587852\n",
      "Epoch [381 / 1200] average loss: 8.880859\n",
      "Epoch [381 / 1200] test loss: 8.638978\n",
      "Epoch [382 / 1200] average loss: 8.985464\n",
      "Epoch [382 / 1200] test loss: 8.569023\n",
      "Epoch [383 / 1200] average loss: 9.048445\n",
      "Epoch [383 / 1200] test loss: 8.616466\n",
      "Epoch [384 / 1200] average loss: 9.139778\n",
      "Epoch [384 / 1200] test loss: 8.884940\n",
      "Epoch [385 / 1200] average loss: 9.027351\n",
      "Epoch [385 / 1200] test loss: 8.693111\n",
      "Epoch [386 / 1200] average loss: 9.107838\n",
      "Epoch [386 / 1200] test loss: 10.358594\n",
      "Epoch [387 / 1200] average loss: 9.043517\n",
      "Epoch [387 / 1200] test loss: 9.067973\n",
      "Epoch [388 / 1200] average loss: 9.097973\n",
      "Epoch [388 / 1200] test loss: 8.600710\n",
      "Epoch [389 / 1200] average loss: 9.167950\n",
      "Epoch [389 / 1200] test loss: 8.463732\n",
      "Epoch [390 / 1200] average loss: 8.962181\n",
      "Epoch [390 / 1200] test loss: 8.773514\n",
      "Epoch [391 / 1200] average loss: 8.988250\n",
      "Epoch [391 / 1200] test loss: 8.662240\n",
      "Epoch [392 / 1200] average loss: 8.971741\n",
      "Epoch [392 / 1200] test loss: 8.450327\n",
      "Epoch [393 / 1200] average loss: 8.934144\n",
      "Epoch [393 / 1200] test loss: 8.616987\n",
      "Epoch [394 / 1200] average loss: 8.937424\n",
      "Epoch [394 / 1200] test loss: 8.779098\n",
      "Epoch [395 / 1200] average loss: 8.869766\n",
      "Epoch [395 / 1200] test loss: 8.669094\n",
      "Epoch [396 / 1200] average loss: 8.962316\n",
      "Epoch [396 / 1200] test loss: 8.457305\n",
      "Epoch [397 / 1200] average loss: 8.928409\n",
      "Epoch [397 / 1200] test loss: 8.491952\n",
      "Epoch [398 / 1200] average loss: 8.732110\n",
      "Epoch [398 / 1200] test loss: 8.491645\n",
      "Epoch [399 / 1200] average loss: 8.795056\n",
      "Epoch [399 / 1200] test loss: 8.588799\n",
      "Epoch [400 / 1200] average loss: 8.805044\n",
      "Epoch [400 / 1200] test loss: 8.612854\n",
      "Epoch [401 / 1200] average loss: 8.743086\n",
      "Epoch [401 / 1200] test loss: 8.526404\n",
      "Epoch [402 / 1200] average loss: 8.804818\n",
      "Epoch [402 / 1200] test loss: 8.730033\n",
      "Epoch [403 / 1200] average loss: 8.966453\n",
      "Epoch [403 / 1200] test loss: 8.380065\n",
      "Epoch [404 / 1200] average loss: 8.724963\n",
      "Epoch [404 / 1200] test loss: 8.427075\n",
      "Epoch [405 / 1200] average loss: 8.816156\n",
      "Epoch [405 / 1200] test loss: 8.744722\n",
      "Epoch [406 / 1200] average loss: 8.945576\n",
      "Epoch [406 / 1200] test loss: 8.294698\n",
      "Epoch [407 / 1200] average loss: 8.952527\n",
      "Epoch [407 / 1200] test loss: 8.617053\n",
      "Epoch [408 / 1200] average loss: 8.827026\n",
      "Epoch [408 / 1200] test loss: 8.377483\n",
      "Epoch [409 / 1200] average loss: 8.870183\n",
      "Epoch [409 / 1200] test loss: 8.460006\n",
      "Epoch [410 / 1200] average loss: 8.745867\n",
      "Epoch [410 / 1200] test loss: 8.779733\n",
      "Epoch [411 / 1200] average loss: 8.728416\n",
      "Epoch [411 / 1200] test loss: 8.378205\n",
      "Epoch [412 / 1200] average loss: 8.716333\n",
      "Epoch [412 / 1200] test loss: 8.380383\n",
      "Epoch [413 / 1200] average loss: 8.685165\n",
      "Epoch [413 / 1200] test loss: 8.271411\n",
      "Epoch [414 / 1200] average loss: 8.791989\n",
      "Epoch [414 / 1200] test loss: 8.204734\n",
      "Epoch [415 / 1200] average loss: 8.784607\n",
      "Epoch [415 / 1200] test loss: 8.304551\n",
      "Epoch [416 / 1200] average loss: 8.595382\n",
      "Epoch [416 / 1200] test loss: 8.347917\n",
      "Epoch [417 / 1200] average loss: 8.575679\n",
      "Epoch [417 / 1200] test loss: 8.364380\n",
      "Epoch [418 / 1200] average loss: 8.650206\n",
      "Epoch [418 / 1200] test loss: 8.326212\n",
      "Epoch [419 / 1200] average loss: 8.678029\n",
      "Epoch [419 / 1200] test loss: 8.284961\n",
      "Epoch [420 / 1200] average loss: 8.619348\n",
      "Epoch [420 / 1200] test loss: 8.282669\n",
      "Epoch [421 / 1200] average loss: 8.641142\n",
      "Epoch [421 / 1200] test loss: 8.237510\n",
      "Epoch [422 / 1200] average loss: 8.841034\n",
      "Epoch [422 / 1200] test loss: 11.019230\n",
      "Epoch [423 / 1200] average loss: 8.712137\n",
      "Epoch [423 / 1200] test loss: 8.431075\n",
      "Epoch [424 / 1200] average loss: 8.760368\n",
      "Epoch [424 / 1200] test loss: 8.254174\n",
      "Epoch [425 / 1200] average loss: 8.699790\n",
      "Epoch [425 / 1200] test loss: 8.352266\n",
      "Epoch [426 / 1200] average loss: 8.747749\n",
      "Epoch [426 / 1200] test loss: 8.278781\n",
      "Epoch [427 / 1200] average loss: 8.741845\n",
      "Epoch [427 / 1200] test loss: 8.079453\n",
      "Epoch [428 / 1200] average loss: 8.670031\n",
      "Epoch [428 / 1200] test loss: 8.156799\n",
      "Epoch [429 / 1200] average loss: 8.611514\n",
      "Epoch [429 / 1200] test loss: 8.301369\n",
      "Epoch [430 / 1200] average loss: 8.606129\n",
      "Epoch [430 / 1200] test loss: 8.261577\n",
      "Epoch [431 / 1200] average loss: 8.548676\n",
      "Epoch [431 / 1200] test loss: 8.122894\n",
      "Epoch [432 / 1200] average loss: 8.509541\n",
      "Epoch [432 / 1200] test loss: 8.231516\n",
      "Epoch [433 / 1200] average loss: 8.554545\n",
      "Epoch [433 / 1200] test loss: 8.118161\n",
      "Epoch [434 / 1200] average loss: 8.574913\n",
      "Epoch [434 / 1200] test loss: 8.146538\n",
      "Epoch [435 / 1200] average loss: 8.758929\n",
      "Epoch [435 / 1200] test loss: 8.172457\n",
      "Epoch [436 / 1200] average loss: 8.672190\n",
      "Epoch [436 / 1200] test loss: 8.179271\n",
      "Epoch [437 / 1200] average loss: 8.793991\n",
      "Epoch [437 / 1200] test loss: 8.114467\n",
      "Epoch [438 / 1200] average loss: 8.529751\n",
      "Epoch [438 / 1200] test loss: 8.050433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [439 / 1200] average loss: 8.609687\n",
      "Epoch [439 / 1200] test loss: 8.114097\n",
      "Epoch [440 / 1200] average loss: 8.457328\n",
      "Epoch [440 / 1200] test loss: 8.056855\n",
      "Epoch [441 / 1200] average loss: 8.514858\n",
      "Epoch [441 / 1200] test loss: 8.073151\n",
      "Epoch [442 / 1200] average loss: 8.428266\n",
      "Epoch [442 / 1200] test loss: 8.252806\n",
      "Epoch [443 / 1200] average loss: 8.448301\n",
      "Epoch [443 / 1200] test loss: 8.103735\n",
      "Epoch [444 / 1200] average loss: 8.467877\n",
      "Epoch [444 / 1200] test loss: 8.062860\n",
      "Epoch [445 / 1200] average loss: 8.480399\n",
      "Epoch [445 / 1200] test loss: 8.200146\n",
      "Epoch [446 / 1200] average loss: 8.308899\n",
      "Epoch [446 / 1200] test loss: 8.109233\n",
      "Epoch [447 / 1200] average loss: 8.384414\n",
      "Epoch [447 / 1200] test loss: 8.137996\n",
      "Epoch [448 / 1200] average loss: 8.400257\n",
      "Epoch [448 / 1200] test loss: 8.190329\n",
      "Epoch [449 / 1200] average loss: 8.300346\n",
      "Epoch [449 / 1200] test loss: 8.006850\n",
      "Epoch [450 / 1200] average loss: 8.449704\n",
      "Epoch [450 / 1200] test loss: 8.032337\n",
      "Epoch [451 / 1200] average loss: 8.337078\n",
      "Epoch [451 / 1200] test loss: 8.011667\n",
      "Epoch [452 / 1200] average loss: 8.395453\n",
      "Epoch [452 / 1200] test loss: 8.114033\n",
      "Epoch [453 / 1200] average loss: 8.471812\n",
      "Epoch [453 / 1200] test loss: 8.086400\n",
      "Epoch [454 / 1200] average loss: 8.342374\n",
      "Epoch [454 / 1200] test loss: 8.217884\n",
      "Epoch [455 / 1200] average loss: 8.559896\n",
      "Epoch [455 / 1200] test loss: 8.227937\n",
      "Epoch [456 / 1200] average loss: 8.565967\n",
      "Epoch [456 / 1200] test loss: 7.907500\n",
      "Epoch [457 / 1200] average loss: 8.291277\n",
      "Epoch [457 / 1200] test loss: 7.935755\n",
      "Epoch [458 / 1200] average loss: 8.366506\n",
      "Epoch [458 / 1200] test loss: 8.152970\n",
      "Epoch [459 / 1200] average loss: 8.370689\n",
      "Epoch [459 / 1200] test loss: 7.915908\n",
      "Epoch [460 / 1200] average loss: 8.309640\n",
      "Epoch [460 / 1200] test loss: 7.991689\n",
      "Epoch [461 / 1200] average loss: 8.406057\n",
      "Epoch [461 / 1200] test loss: 7.874904\n",
      "Epoch [462 / 1200] average loss: 8.224987\n",
      "Epoch [462 / 1200] test loss: 7.747696\n",
      "Epoch [463 / 1200] average loss: 8.168436\n",
      "Epoch [463 / 1200] test loss: 7.794328\n",
      "Epoch [464 / 1200] average loss: 8.188049\n",
      "Epoch [464 / 1200] test loss: 7.766434\n",
      "Epoch [465 / 1200] average loss: 8.149145\n",
      "Epoch [465 / 1200] test loss: 7.617213\n",
      "Epoch [466 / 1200] average loss: 8.180107\n",
      "Epoch [466 / 1200] test loss: 7.747746\n",
      "Epoch [467 / 1200] average loss: 8.157580\n",
      "Epoch [467 / 1200] test loss: 7.740076\n",
      "Epoch [468 / 1200] average loss: 8.176345\n",
      "Epoch [468 / 1200] test loss: 7.781037\n",
      "Epoch [469 / 1200] average loss: 8.054664\n",
      "Epoch [469 / 1200] test loss: 7.833041\n",
      "Epoch [470 / 1200] average loss: 8.311110\n",
      "Epoch [470 / 1200] test loss: 7.747715\n",
      "Epoch [471 / 1200] average loss: 8.626897\n",
      "Epoch [471 / 1200] test loss: 10.613782\n",
      "Epoch [472 / 1200] average loss: 9.517238\n",
      "Epoch [472 / 1200] test loss: 9.569621\n",
      "Epoch [473 / 1200] average loss: 9.110746\n",
      "Epoch [473 / 1200] test loss: 7.933753\n",
      "Epoch [474 / 1200] average loss: 8.933792\n",
      "Epoch [474 / 1200] test loss: 7.706187\n",
      "Epoch [475 / 1200] average loss: 8.734805\n",
      "Epoch [475 / 1200] test loss: 8.022219\n",
      "Epoch [476 / 1200] average loss: 8.498256\n",
      "Epoch [476 / 1200] test loss: 8.113419\n",
      "Epoch [477 / 1200] average loss: 8.328456\n",
      "Epoch [477 / 1200] test loss: 7.965164\n",
      "Epoch [478 / 1200] average loss: 8.199298\n",
      "Epoch [478 / 1200] test loss: 7.787816\n",
      "Epoch [479 / 1200] average loss: 8.212802\n",
      "Epoch [479 / 1200] test loss: 7.742511\n",
      "Epoch [480 / 1200] average loss: 8.217608\n",
      "Epoch [480 / 1200] test loss: 7.842633\n",
      "Epoch [481 / 1200] average loss: 8.209448\n",
      "Epoch [481 / 1200] test loss: 7.880899\n",
      "Epoch [482 / 1200] average loss: 8.146867\n",
      "Epoch [482 / 1200] test loss: 7.775156\n",
      "Epoch [483 / 1200] average loss: 8.304671\n",
      "Epoch [483 / 1200] test loss: 7.869085\n",
      "Epoch [484 / 1200] average loss: 8.074944\n",
      "Epoch [484 / 1200] test loss: 7.691800\n",
      "Epoch [485 / 1200] average loss: 8.103396\n",
      "Epoch [485 / 1200] test loss: 7.728369\n",
      "Epoch [486 / 1200] average loss: 8.116746\n",
      "Epoch [486 / 1200] test loss: 7.689396\n",
      "Epoch [487 / 1200] average loss: 8.023776\n",
      "Epoch [487 / 1200] test loss: 7.615083\n",
      "Epoch [488 / 1200] average loss: 8.059210\n",
      "Epoch [488 / 1200] test loss: 7.720978\n",
      "Epoch [489 / 1200] average loss: 8.167151\n",
      "Epoch [489 / 1200] test loss: 7.556325\n",
      "Epoch [490 / 1200] average loss: 7.983070\n",
      "Epoch [490 / 1200] test loss: 7.535919\n",
      "Epoch [491 / 1200] average loss: 8.081175\n",
      "Epoch [491 / 1200] test loss: 7.566725\n",
      "Epoch [492 / 1200] average loss: 8.023581\n",
      "Epoch [492 / 1200] test loss: 7.583997\n",
      "Epoch [493 / 1200] average loss: 8.058337\n",
      "Epoch [493 / 1200] test loss: 7.505269\n",
      "Epoch [494 / 1200] average loss: 7.970212\n",
      "Epoch [494 / 1200] test loss: 7.630284\n",
      "Epoch [495 / 1200] average loss: 7.977404\n",
      "Epoch [495 / 1200] test loss: 7.521480\n",
      "Epoch [496 / 1200] average loss: 7.993886\n",
      "Epoch [496 / 1200] test loss: 7.475262\n",
      "Epoch [497 / 1200] average loss: 8.106759\n",
      "Epoch [497 / 1200] test loss: 7.525575\n",
      "Epoch [498 / 1200] average loss: 7.989020\n",
      "Epoch [498 / 1200] test loss: 7.525034\n",
      "Epoch [499 / 1200] average loss: 8.020950\n",
      "Epoch [499 / 1200] test loss: 7.517659\n",
      "Epoch [500 / 1200] average loss: 7.879671\n",
      "Epoch [500 / 1200] test loss: 7.457481\n",
      "Epoch [501 / 1200] average loss: 7.875958\n",
      "Epoch [501 / 1200] test loss: 7.454763\n",
      "Epoch [502 / 1200] average loss: 7.912434\n",
      "Epoch [502 / 1200] test loss: 7.460685\n",
      "Epoch [503 / 1200] average loss: 7.924055\n",
      "Epoch [503 / 1200] test loss: 7.449940\n",
      "Epoch [504 / 1200] average loss: 7.965254\n",
      "Epoch [504 / 1200] test loss: 7.498242\n",
      "Epoch [505 / 1200] average loss: 7.889684\n",
      "Epoch [505 / 1200] test loss: 7.470728\n",
      "Epoch [506 / 1200] average loss: 7.764600\n",
      "Epoch [506 / 1200] test loss: 7.341855\n",
      "Epoch [507 / 1200] average loss: 7.871957\n",
      "Epoch [507 / 1200] test loss: 7.415696\n",
      "Epoch [508 / 1200] average loss: 7.934458\n",
      "Epoch [508 / 1200] test loss: 7.561850\n",
      "Epoch [509 / 1200] average loss: 7.943619\n",
      "Epoch [509 / 1200] test loss: 7.585631\n",
      "Epoch [510 / 1200] average loss: 7.848866\n",
      "Epoch [510 / 1200] test loss: 7.295137\n",
      "Epoch [511 / 1200] average loss: 7.899575\n",
      "Epoch [511 / 1200] test loss: 7.396917\n",
      "Epoch [512 / 1200] average loss: 7.744205\n",
      "Epoch [512 / 1200] test loss: 7.287767\n",
      "Epoch [513 / 1200] average loss: 7.699196\n",
      "Epoch [513 / 1200] test loss: 7.219981\n",
      "Epoch [514 / 1200] average loss: 7.699033\n",
      "Epoch [514 / 1200] test loss: 7.212653\n",
      "Epoch [515 / 1200] average loss: 7.683610\n",
      "Epoch [515 / 1200] test loss: 7.245593\n",
      "Epoch [516 / 1200] average loss: 7.700756\n",
      "Epoch [516 / 1200] test loss: 7.342426\n",
      "Epoch [517 / 1200] average loss: 7.696455\n",
      "Epoch [517 / 1200] test loss: 7.318721\n",
      "Epoch [518 / 1200] average loss: 7.845688\n",
      "Epoch [518 / 1200] test loss: 7.220326\n",
      "Epoch [519 / 1200] average loss: 7.767814\n",
      "Epoch [519 / 1200] test loss: 7.227221\n",
      "Epoch [520 / 1200] average loss: 7.545525\n",
      "Epoch [520 / 1200] test loss: 7.433762\n",
      "Epoch [521 / 1200] average loss: 7.675258\n",
      "Epoch [521 / 1200] test loss: 7.213205\n",
      "Epoch [522 / 1200] average loss: 7.706445\n",
      "Epoch [522 / 1200] test loss: 7.164858\n",
      "Epoch [523 / 1200] average loss: 7.585957\n",
      "Epoch [523 / 1200] test loss: 7.087771\n",
      "Epoch [524 / 1200] average loss: 7.714387\n",
      "Epoch [524 / 1200] test loss: 7.149237\n",
      "Epoch [525 / 1200] average loss: 7.703171\n",
      "Epoch [525 / 1200] test loss: 7.176200\n",
      "Epoch [526 / 1200] average loss: 7.719248\n",
      "Epoch [526 / 1200] test loss: 7.126542\n",
      "Epoch [527 / 1200] average loss: 7.624069\n",
      "Epoch [527 / 1200] test loss: 7.164655\n",
      "Epoch [528 / 1200] average loss: 7.582680\n",
      "Epoch [528 / 1200] test loss: 7.022572\n",
      "Epoch [529 / 1200] average loss: 7.585073\n",
      "Epoch [529 / 1200] test loss: 7.144939\n",
      "Epoch [530 / 1200] average loss: 7.604666\n",
      "Epoch [530 / 1200] test loss: 7.238651\n",
      "Epoch [531 / 1200] average loss: 7.426538\n",
      "Epoch [531 / 1200] test loss: 7.165006\n",
      "Epoch [532 / 1200] average loss: 7.568801\n",
      "Epoch [532 / 1200] test loss: 7.081469\n",
      "Epoch [533 / 1200] average loss: 7.507215\n",
      "Epoch [533 / 1200] test loss: 7.050544\n",
      "Epoch [534 / 1200] average loss: 7.532765\n",
      "Epoch [534 / 1200] test loss: 7.030383\n",
      "Epoch [535 / 1200] average loss: 7.565980\n",
      "Epoch [535 / 1200] test loss: 7.077388\n",
      "Epoch [536 / 1200] average loss: 7.560024\n",
      "Epoch [536 / 1200] test loss: 7.185919\n",
      "Epoch [537 / 1200] average loss: 7.669265\n",
      "Epoch [537 / 1200] test loss: 7.311769\n",
      "Epoch [538 / 1200] average loss: 7.679624\n",
      "Epoch [538 / 1200] test loss: 7.289725\n",
      "Epoch [539 / 1200] average loss: 7.702176\n",
      "Epoch [539 / 1200] test loss: 7.046300\n",
      "Epoch [540 / 1200] average loss: 7.739564\n",
      "Epoch [540 / 1200] test loss: 7.129313\n",
      "Epoch [541 / 1200] average loss: 7.497228\n",
      "Epoch [541 / 1200] test loss: 7.106944\n",
      "Epoch [542 / 1200] average loss: 7.609491\n",
      "Epoch [542 / 1200] test loss: 7.305501\n",
      "Epoch [543 / 1200] average loss: 7.710712\n",
      "Epoch [543 / 1200] test loss: 7.011989\n",
      "Epoch [544 / 1200] average loss: 7.654284\n",
      "Epoch [544 / 1200] test loss: 7.164341\n",
      "Epoch [545 / 1200] average loss: 7.610071\n",
      "Epoch [545 / 1200] test loss: 7.020277\n",
      "Epoch [546 / 1200] average loss: 7.628732\n",
      "Epoch [546 / 1200] test loss: 7.274973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [547 / 1200] average loss: 7.508904\n",
      "Epoch [547 / 1200] test loss: 6.946172\n",
      "Epoch [548 / 1200] average loss: 7.540383\n",
      "Epoch [548 / 1200] test loss: 7.058714\n",
      "Epoch [549 / 1200] average loss: 7.634538\n",
      "Epoch [549 / 1200] test loss: 7.152932\n",
      "Epoch [550 / 1200] average loss: 7.412813\n",
      "Epoch [550 / 1200] test loss: 6.981646\n",
      "Epoch [551 / 1200] average loss: 7.480915\n",
      "Epoch [551 / 1200] test loss: 7.060673\n",
      "Epoch [552 / 1200] average loss: 7.442635\n",
      "Epoch [552 / 1200] test loss: 7.109225\n",
      "Epoch [553 / 1200] average loss: 7.459235\n",
      "Epoch [553 / 1200] test loss: 7.139896\n",
      "Epoch [554 / 1200] average loss: 7.439353\n",
      "Epoch [554 / 1200] test loss: 7.050778\n",
      "Epoch [555 / 1200] average loss: 7.459767\n",
      "Epoch [555 / 1200] test loss: 6.925702\n",
      "Epoch [556 / 1200] average loss: 7.399748\n",
      "Epoch [556 / 1200] test loss: 7.008545\n",
      "Epoch [557 / 1200] average loss: 7.338726\n",
      "Epoch [557 / 1200] test loss: 6.991846\n",
      "Epoch [558 / 1200] average loss: 7.443069\n",
      "Epoch [558 / 1200] test loss: 7.059256\n",
      "Epoch [559 / 1200] average loss: 7.284865\n",
      "Epoch [559 / 1200] test loss: 6.943954\n",
      "Epoch [560 / 1200] average loss: 7.332503\n",
      "Epoch [560 / 1200] test loss: 6.886352\n",
      "Epoch [561 / 1200] average loss: 7.408318\n",
      "Epoch [561 / 1200] test loss: 6.824538\n",
      "Epoch [562 / 1200] average loss: 7.316924\n",
      "Epoch [562 / 1200] test loss: 6.789250\n",
      "Epoch [563 / 1200] average loss: 7.288780\n",
      "Epoch [563 / 1200] test loss: 6.834764\n",
      "Epoch [564 / 1200] average loss: 7.201537\n",
      "Epoch [564 / 1200] test loss: 6.868759\n",
      "Epoch [565 / 1200] average loss: 7.282551\n",
      "Epoch [565 / 1200] test loss: 6.836494\n",
      "Epoch [566 / 1200] average loss: 7.229694\n",
      "Epoch [566 / 1200] test loss: 6.939835\n",
      "Epoch [567 / 1200] average loss: 7.442573\n",
      "Epoch [567 / 1200] test loss: 6.806424\n",
      "Epoch [568 / 1200] average loss: 7.211441\n",
      "Epoch [568 / 1200] test loss: 6.852655\n",
      "Epoch [569 / 1200] average loss: 7.156030\n",
      "Epoch [569 / 1200] test loss: 6.655314\n",
      "Epoch [570 / 1200] average loss: 7.221914\n",
      "Epoch [570 / 1200] test loss: 6.878337\n",
      "Epoch [571 / 1200] average loss: 7.256052\n",
      "Epoch [571 / 1200] test loss: 6.711495\n",
      "Epoch [572 / 1200] average loss: 7.087616\n",
      "Epoch [572 / 1200] test loss: 6.817433\n",
      "Epoch [573 / 1200] average loss: 7.269095\n",
      "Epoch [573 / 1200] test loss: 6.875733\n",
      "Epoch [574 / 1200] average loss: 7.385350\n",
      "Epoch [574 / 1200] test loss: 7.906555\n",
      "Epoch [575 / 1200] average loss: 8.609905\n",
      "Epoch [575 / 1200] test loss: 10.392925\n",
      "Epoch [576 / 1200] average loss: 10.074062\n",
      "Epoch [576 / 1200] test loss: 7.160581\n",
      "Epoch [577 / 1200] average loss: 8.109483\n",
      "Epoch [577 / 1200] test loss: 7.469106\n",
      "Epoch [578 / 1200] average loss: 8.547379\n",
      "Epoch [578 / 1200] test loss: 7.314854\n",
      "Epoch [579 / 1200] average loss: 8.830463\n",
      "Epoch [579 / 1200] test loss: 6.970299\n",
      "Epoch [580 / 1200] average loss: 8.655418\n",
      "Epoch [580 / 1200] test loss: 7.428297\n",
      "Epoch [581 / 1200] average loss: 8.578746\n",
      "Epoch [581 / 1200] test loss: 7.522678\n",
      "Epoch [582 / 1200] average loss: 7.909114\n",
      "Epoch [582 / 1200] test loss: 7.627867\n",
      "Epoch [583 / 1200] average loss: 7.908057\n",
      "Epoch [583 / 1200] test loss: 7.169685\n",
      "Epoch [584 / 1200] average loss: 7.927170\n",
      "Epoch [584 / 1200] test loss: 6.976293\n",
      "Epoch [585 / 1200] average loss: 7.587707\n",
      "Epoch [585 / 1200] test loss: 7.156805\n",
      "Epoch [586 / 1200] average loss: 7.577521\n",
      "Epoch [586 / 1200] test loss: 6.935981\n",
      "Epoch [587 / 1200] average loss: 7.466661\n",
      "Epoch [587 / 1200] test loss: 6.981205\n",
      "Epoch [588 / 1200] average loss: 7.278711\n",
      "Epoch [588 / 1200] test loss: 6.958062\n",
      "Epoch [589 / 1200] average loss: 7.441424\n",
      "Epoch [589 / 1200] test loss: 6.835796\n",
      "Epoch [590 / 1200] average loss: 7.278463\n",
      "Epoch [590 / 1200] test loss: 7.005180\n",
      "Epoch [591 / 1200] average loss: 7.315033\n",
      "Epoch [591 / 1200] test loss: 6.962445\n",
      "Epoch [592 / 1200] average loss: 7.228340\n",
      "Epoch [592 / 1200] test loss: 6.918969\n",
      "Epoch [593 / 1200] average loss: 7.224672\n",
      "Epoch [593 / 1200] test loss: 6.910066\n",
      "Epoch [594 / 1200] average loss: 7.183640\n",
      "Epoch [594 / 1200] test loss: 6.809860\n",
      "Epoch [595 / 1200] average loss: 7.232791\n",
      "Epoch [595 / 1200] test loss: 6.908427\n",
      "Epoch [596 / 1200] average loss: 7.140481\n",
      "Epoch [596 / 1200] test loss: 6.822410\n",
      "Epoch [597 / 1200] average loss: 7.275385\n",
      "Epoch [597 / 1200] test loss: 6.798674\n",
      "Epoch [598 / 1200] average loss: 7.159524\n",
      "Epoch [598 / 1200] test loss: 6.952551\n",
      "Epoch [599 / 1200] average loss: 7.156477\n",
      "Epoch [599 / 1200] test loss: 6.808696\n",
      "Epoch [600 / 1200] average loss: 7.159022\n",
      "Epoch [600 / 1200] test loss: 6.724679\n",
      "Epoch [601 / 1200] average loss: 7.212808\n",
      "Epoch [601 / 1200] test loss: 6.790373\n",
      "Epoch [602 / 1200] average loss: 7.171135\n",
      "Epoch [602 / 1200] test loss: 6.811315\n",
      "Epoch [603 / 1200] average loss: 7.211231\n",
      "Epoch [603 / 1200] test loss: 6.866176\n",
      "Epoch [604 / 1200] average loss: 7.079549\n",
      "Epoch [604 / 1200] test loss: 6.830752\n",
      "Epoch [605 / 1200] average loss: 7.150661\n",
      "Epoch [605 / 1200] test loss: 6.877499\n",
      "Epoch [606 / 1200] average loss: 7.111927\n",
      "Epoch [606 / 1200] test loss: 6.713668\n",
      "Epoch [607 / 1200] average loss: 7.070456\n",
      "Epoch [607 / 1200] test loss: 6.789454\n",
      "Epoch [608 / 1200] average loss: 7.048171\n",
      "Epoch [608 / 1200] test loss: 6.697661\n",
      "Epoch [609 / 1200] average loss: 7.167906\n",
      "Epoch [609 / 1200] test loss: 6.727637\n",
      "Epoch [610 / 1200] average loss: 7.025456\n",
      "Epoch [610 / 1200] test loss: 6.824887\n",
      "Epoch [611 / 1200] average loss: 7.243270\n",
      "Epoch [611 / 1200] test loss: 6.749248\n",
      "Epoch [612 / 1200] average loss: 7.232920\n",
      "Epoch [612 / 1200] test loss: 6.584428\n",
      "Epoch [613 / 1200] average loss: 7.037485\n",
      "Epoch [613 / 1200] test loss: 6.641572\n",
      "Epoch [614 / 1200] average loss: 6.925674\n",
      "Epoch [614 / 1200] test loss: 6.770649\n",
      "Epoch [615 / 1200] average loss: 6.970073\n",
      "Epoch [615 / 1200] test loss: 6.642993\n",
      "Epoch [616 / 1200] average loss: 6.990883\n",
      "Epoch [616 / 1200] test loss: 6.565621\n",
      "Epoch [617 / 1200] average loss: 7.022619\n",
      "Epoch [617 / 1200] test loss: 6.612606\n",
      "Epoch [618 / 1200] average loss: 7.103298\n",
      "Epoch [618 / 1200] test loss: 6.831028\n",
      "Epoch [619 / 1200] average loss: 7.046123\n",
      "Epoch [619 / 1200] test loss: 6.871609\n",
      "Epoch [620 / 1200] average loss: 7.026128\n",
      "Epoch [620 / 1200] test loss: 6.616709\n",
      "Epoch [621 / 1200] average loss: 7.032244\n",
      "Epoch [621 / 1200] test loss: 6.669070\n",
      "Epoch [622 / 1200] average loss: 6.973712\n",
      "Epoch [622 / 1200] test loss: 6.744724\n",
      "Epoch [623 / 1200] average loss: 6.995568\n",
      "Epoch [623 / 1200] test loss: 6.627101\n",
      "Epoch [624 / 1200] average loss: 6.985505\n",
      "Epoch [624 / 1200] test loss: 6.641815\n",
      "Epoch [625 / 1200] average loss: 6.942404\n",
      "Epoch [625 / 1200] test loss: 6.528133\n",
      "Epoch [626 / 1200] average loss: 7.016271\n",
      "Epoch [626 / 1200] test loss: 6.717920\n",
      "Epoch [627 / 1200] average loss: 7.013067\n",
      "Epoch [627 / 1200] test loss: 6.621423\n",
      "Epoch [628 / 1200] average loss: 6.941379\n",
      "Epoch [628 / 1200] test loss: 6.666321\n",
      "Epoch [629 / 1200] average loss: 6.920901\n",
      "Epoch [629 / 1200] test loss: 6.842684\n",
      "Epoch [630 / 1200] average loss: 6.886741\n",
      "Epoch [630 / 1200] test loss: 6.693800\n",
      "Epoch [631 / 1200] average loss: 6.894623\n",
      "Epoch [631 / 1200] test loss: 6.650623\n",
      "Epoch [632 / 1200] average loss: 7.009673\n",
      "Epoch [632 / 1200] test loss: 6.571358\n",
      "Epoch [633 / 1200] average loss: 6.927672\n",
      "Epoch [633 / 1200] test loss: 6.652319\n",
      "Epoch [634 / 1200] average loss: 6.842103\n",
      "Epoch [634 / 1200] test loss: 6.699556\n",
      "Epoch [635 / 1200] average loss: 7.059805\n",
      "Epoch [635 / 1200] test loss: 6.682762\n",
      "Epoch [636 / 1200] average loss: 6.864844\n",
      "Epoch [636 / 1200] test loss: 6.512938\n",
      "Epoch [637 / 1200] average loss: 6.669233\n",
      "Epoch [637 / 1200] test loss: 6.580102\n",
      "Epoch [638 / 1200] average loss: 6.815629\n",
      "Epoch [638 / 1200] test loss: 6.415547\n",
      "Epoch [639 / 1200] average loss: 6.788285\n",
      "Epoch [639 / 1200] test loss: 6.812211\n",
      "Epoch [640 / 1200] average loss: 6.848756\n",
      "Epoch [640 / 1200] test loss: 6.543563\n",
      "Epoch [641 / 1200] average loss: 6.666106\n",
      "Epoch [641 / 1200] test loss: 6.556949\n",
      "Epoch [642 / 1200] average loss: 6.687046\n",
      "Epoch [642 / 1200] test loss: 6.505660\n",
      "Epoch [643 / 1200] average loss: 6.732792\n",
      "Epoch [643 / 1200] test loss: 6.739493\n",
      "Epoch [644 / 1200] average loss: 6.713023\n",
      "Epoch [644 / 1200] test loss: 6.579245\n",
      "Epoch [645 / 1200] average loss: 6.790302\n",
      "Epoch [645 / 1200] test loss: 6.590545\n",
      "Epoch [646 / 1200] average loss: 6.751229\n",
      "Epoch [646 / 1200] test loss: 6.578730\n",
      "Epoch [647 / 1200] average loss: 6.759753\n",
      "Epoch [647 / 1200] test loss: 6.453224\n",
      "Epoch [648 / 1200] average loss: 6.731913\n",
      "Epoch [648 / 1200] test loss: 6.473056\n",
      "Epoch [649 / 1200] average loss: 6.789664\n",
      "Epoch [649 / 1200] test loss: 6.521967\n",
      "Epoch [650 / 1200] average loss: 6.869135\n",
      "Epoch [650 / 1200] test loss: 6.621005\n",
      "Epoch [651 / 1200] average loss: 6.747027\n",
      "Epoch [651 / 1200] test loss: 6.528705\n",
      "Epoch [652 / 1200] average loss: 6.759566\n",
      "Epoch [652 / 1200] test loss: 6.638334\n",
      "Epoch [653 / 1200] average loss: 6.591143\n",
      "Epoch [653 / 1200] test loss: 6.624621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [654 / 1200] average loss: 6.793582\n",
      "Epoch [654 / 1200] test loss: 6.560975\n",
      "Epoch [655 / 1200] average loss: 6.724299\n",
      "Epoch [655 / 1200] test loss: 6.542947\n",
      "Epoch [656 / 1200] average loss: 6.753127\n",
      "Epoch [656 / 1200] test loss: 6.443194\n",
      "Epoch [657 / 1200] average loss: 6.829833\n",
      "Epoch [657 / 1200] test loss: 6.576868\n",
      "Epoch [658 / 1200] average loss: 6.700782\n",
      "Epoch [658 / 1200] test loss: 6.325893\n",
      "Epoch [659 / 1200] average loss: 6.657684\n",
      "Epoch [659 / 1200] test loss: 6.538308\n",
      "Epoch [660 / 1200] average loss: 6.578653\n",
      "Epoch [660 / 1200] test loss: 6.401531\n",
      "Epoch [661 / 1200] average loss: 6.743744\n",
      "Epoch [661 / 1200] test loss: 6.440906\n",
      "Epoch [662 / 1200] average loss: 6.609022\n",
      "Epoch [662 / 1200] test loss: 6.502272\n",
      "Epoch [663 / 1200] average loss: 6.614358\n",
      "Epoch [663 / 1200] test loss: 6.424979\n",
      "Epoch [664 / 1200] average loss: 6.627003\n",
      "Epoch [664 / 1200] test loss: 6.593229\n",
      "Epoch [665 / 1200] average loss: 6.640536\n",
      "Epoch [665 / 1200] test loss: 6.522506\n",
      "Epoch [666 / 1200] average loss: 6.577443\n",
      "Epoch [666 / 1200] test loss: 6.461086\n",
      "Epoch [667 / 1200] average loss: 6.638811\n",
      "Epoch [667 / 1200] test loss: 6.351298\n",
      "Epoch [668 / 1200] average loss: 6.538524\n",
      "Epoch [668 / 1200] test loss: 6.537209\n",
      "Epoch [669 / 1200] average loss: 6.617414\n",
      "Epoch [669 / 1200] test loss: 6.339995\n",
      "Epoch [670 / 1200] average loss: 6.483316\n",
      "Epoch [670 / 1200] test loss: 6.609922\n",
      "Epoch [671 / 1200] average loss: 6.668819\n",
      "Epoch [671 / 1200] test loss: 6.492453\n",
      "Epoch [672 / 1200] average loss: 6.528009\n",
      "Epoch [672 / 1200] test loss: 6.324586\n",
      "Epoch [673 / 1200] average loss: 6.446421\n",
      "Epoch [673 / 1200] test loss: 6.527265\n",
      "Epoch [674 / 1200] average loss: 6.526708\n",
      "Epoch [674 / 1200] test loss: 6.654615\n",
      "Epoch [675 / 1200] average loss: 6.668419\n",
      "Epoch [675 / 1200] test loss: 6.417235\n",
      "Epoch [676 / 1200] average loss: 6.388578\n",
      "Epoch [676 / 1200] test loss: 6.301730\n",
      "Epoch [677 / 1200] average loss: 6.579563\n",
      "Epoch [677 / 1200] test loss: 6.527898\n",
      "Epoch [678 / 1200] average loss: 6.490061\n",
      "Epoch [678 / 1200] test loss: 6.489483\n",
      "Epoch [679 / 1200] average loss: 6.630319\n",
      "Epoch [679 / 1200] test loss: 6.452549\n",
      "Epoch [680 / 1200] average loss: 6.531389\n",
      "Epoch [680 / 1200] test loss: 6.334108\n",
      "Epoch [681 / 1200] average loss: 6.463127\n",
      "Epoch [681 / 1200] test loss: 6.348919\n",
      "Epoch [682 / 1200] average loss: 6.435433\n",
      "Epoch [682 / 1200] test loss: 6.486934\n",
      "Epoch [683 / 1200] average loss: 6.541504\n",
      "Epoch [683 / 1200] test loss: 6.300492\n",
      "Epoch [684 / 1200] average loss: 6.490455\n",
      "Epoch [684 / 1200] test loss: 6.394036\n",
      "Epoch [685 / 1200] average loss: 6.554924\n",
      "Epoch [685 / 1200] test loss: 6.577293\n",
      "Epoch [686 / 1200] average loss: 6.327559\n",
      "Epoch [686 / 1200] test loss: 6.207436\n",
      "Epoch [687 / 1200] average loss: 6.609390\n",
      "Epoch [687 / 1200] test loss: 6.273354\n",
      "Epoch [688 / 1200] average loss: 6.471915\n",
      "Epoch [688 / 1200] test loss: 6.384488\n",
      "Epoch [689 / 1200] average loss: 6.517887\n",
      "Epoch [689 / 1200] test loss: 6.568962\n",
      "Epoch [690 / 1200] average loss: 6.870558\n",
      "Epoch [690 / 1200] test loss: 7.980991\n",
      "Epoch [691 / 1200] average loss: 8.381701\n",
      "Epoch [691 / 1200] test loss: 9.194956\n",
      "Epoch [692 / 1200] average loss: 9.130094\n",
      "Epoch [692 / 1200] test loss: 6.763428\n",
      "Epoch [693 / 1200] average loss: 7.605617\n",
      "Epoch [693 / 1200] test loss: 7.111175\n",
      "Epoch [694 / 1200] average loss: 7.512431\n",
      "Epoch [694 / 1200] test loss: 7.153094\n",
      "Epoch [695 / 1200] average loss: 7.209987\n",
      "Epoch [695 / 1200] test loss: 7.002221\n",
      "Epoch [696 / 1200] average loss: 7.055851\n",
      "Epoch [696 / 1200] test loss: 6.798870\n",
      "Epoch [697 / 1200] average loss: 6.971101\n",
      "Epoch [697 / 1200] test loss: 6.501137\n",
      "Epoch [698 / 1200] average loss: 6.852397\n",
      "Epoch [698 / 1200] test loss: 6.425003\n",
      "Epoch [699 / 1200] average loss: 6.818979\n",
      "Epoch [699 / 1200] test loss: 6.352813\n",
      "Epoch [700 / 1200] average loss: 6.927416\n",
      "Epoch [700 / 1200] test loss: 6.404559\n",
      "Epoch [701 / 1200] average loss: 6.886634\n",
      "Epoch [701 / 1200] test loss: 6.429949\n",
      "Epoch [702 / 1200] average loss: 7.100482\n",
      "Epoch [702 / 1200] test loss: 6.587904\n",
      "Epoch [703 / 1200] average loss: 7.145715\n",
      "Epoch [703 / 1200] test loss: 6.426500\n",
      "Epoch [704 / 1200] average loss: 7.318772\n",
      "Epoch [704 / 1200] test loss: 6.707228\n",
      "Epoch [705 / 1200] average loss: 7.342493\n",
      "Epoch [705 / 1200] test loss: 6.607775\n",
      "Epoch [706 / 1200] average loss: 7.233274\n",
      "Epoch [706 / 1200] test loss: 6.870926\n",
      "Epoch [707 / 1200] average loss: 7.006351\n",
      "Epoch [707 / 1200] test loss: 6.866094\n",
      "Epoch [708 / 1200] average loss: 6.791503\n",
      "Epoch [708 / 1200] test loss: 6.528806\n",
      "Epoch [709 / 1200] average loss: 6.673805\n",
      "Epoch [709 / 1200] test loss: 6.613595\n",
      "Epoch [710 / 1200] average loss: 6.623318\n",
      "Epoch [710 / 1200] test loss: 6.343093\n",
      "Epoch [711 / 1200] average loss: 6.559073\n",
      "Epoch [711 / 1200] test loss: 6.310215\n",
      "Epoch [712 / 1200] average loss: 6.551696\n",
      "Epoch [712 / 1200] test loss: 6.302154\n",
      "Epoch [713 / 1200] average loss: 6.604846\n",
      "Epoch [713 / 1200] test loss: 6.484419\n",
      "Epoch [714 / 1200] average loss: 6.452408\n",
      "Epoch [714 / 1200] test loss: 6.475569\n",
      "Epoch [715 / 1200] average loss: 6.552334\n",
      "Epoch [715 / 1200] test loss: 6.461984\n",
      "Epoch [716 / 1200] average loss: 6.629584\n",
      "Epoch [716 / 1200] test loss: 6.475763\n",
      "Epoch [717 / 1200] average loss: 6.516082\n",
      "Epoch [717 / 1200] test loss: 6.323930\n",
      "Epoch [718 / 1200] average loss: 6.466003\n",
      "Epoch [718 / 1200] test loss: 6.427339\n",
      "Epoch [719 / 1200] average loss: 6.527781\n",
      "Epoch [719 / 1200] test loss: 6.499101\n",
      "Epoch [720 / 1200] average loss: 6.414385\n",
      "Epoch [720 / 1200] test loss: 6.500620\n",
      "Epoch [721 / 1200] average loss: 6.416790\n",
      "Epoch [721 / 1200] test loss: 6.316689\n",
      "Epoch [722 / 1200] average loss: 6.456406\n",
      "Epoch [722 / 1200] test loss: 6.401268\n",
      "Epoch [723 / 1200] average loss: 6.599120\n",
      "Epoch [723 / 1200] test loss: 6.508405\n",
      "Epoch [724 / 1200] average loss: 6.412834\n",
      "Epoch [724 / 1200] test loss: 6.375815\n",
      "Epoch [725 / 1200] average loss: 6.534463\n",
      "Epoch [725 / 1200] test loss: 6.418604\n",
      "Epoch [726 / 1200] average loss: 6.488885\n",
      "Epoch [726 / 1200] test loss: 6.314278\n",
      "Epoch [727 / 1200] average loss: 6.471736\n",
      "Epoch [727 / 1200] test loss: 6.347345\n",
      "Epoch [728 / 1200] average loss: 6.428509\n",
      "Epoch [728 / 1200] test loss: 6.541410\n",
      "Epoch [729 / 1200] average loss: 6.501755\n",
      "Epoch [729 / 1200] test loss: 6.458487\n",
      "Epoch [730 / 1200] average loss: 6.439241\n",
      "Epoch [730 / 1200] test loss: 6.469718\n",
      "Epoch [731 / 1200] average loss: 6.451338\n",
      "Epoch [731 / 1200] test loss: 6.402199\n",
      "Epoch [732 / 1200] average loss: 6.388512\n",
      "Epoch [732 / 1200] test loss: 6.565626\n",
      "Epoch [733 / 1200] average loss: 6.349624\n",
      "Epoch [733 / 1200] test loss: 6.409879\n",
      "Epoch [734 / 1200] average loss: 6.612614\n",
      "Epoch [734 / 1200] test loss: 6.344070\n",
      "Epoch [735 / 1200] average loss: 6.499087\n",
      "Epoch [735 / 1200] test loss: 6.474096\n",
      "Epoch [736 / 1200] average loss: 6.456227\n",
      "Epoch [736 / 1200] test loss: 6.501906\n",
      "Epoch [737 / 1200] average loss: 6.376679\n",
      "Epoch [737 / 1200] test loss: 6.155247\n",
      "Epoch [738 / 1200] average loss: 6.290984\n",
      "Epoch [738 / 1200] test loss: 6.512728\n",
      "Epoch [739 / 1200] average loss: 6.547220\n",
      "Epoch [739 / 1200] test loss: 6.438495\n",
      "Epoch [740 / 1200] average loss: 6.363114\n",
      "Epoch [740 / 1200] test loss: 6.531835\n",
      "Epoch [741 / 1200] average loss: 6.473634\n",
      "Epoch [741 / 1200] test loss: 6.485738\n",
      "Epoch [742 / 1200] average loss: 6.378448\n",
      "Epoch [742 / 1200] test loss: 6.616616\n",
      "Epoch [743 / 1200] average loss: 6.394415\n",
      "Epoch [743 / 1200] test loss: 6.299462\n",
      "Epoch [744 / 1200] average loss: 6.400842\n",
      "Epoch [744 / 1200] test loss: 6.213283\n",
      "Epoch [745 / 1200] average loss: 6.522277\n",
      "Epoch [745 / 1200] test loss: 6.403364\n",
      "Epoch [746 / 1200] average loss: 6.427177\n",
      "Epoch [746 / 1200] test loss: 6.410738\n",
      "Epoch [747 / 1200] average loss: 6.430840\n",
      "Epoch [747 / 1200] test loss: 6.515691\n",
      "Epoch [748 / 1200] average loss: 6.315801\n",
      "Epoch [748 / 1200] test loss: 6.296253\n",
      "Epoch [749 / 1200] average loss: 6.324965\n",
      "Epoch [749 / 1200] test loss: 6.392369\n",
      "Epoch [750 / 1200] average loss: 6.432646\n",
      "Epoch [750 / 1200] test loss: 6.536420\n",
      "Epoch [751 / 1200] average loss: 6.316134\n",
      "Epoch [751 / 1200] test loss: 6.316048\n",
      "Epoch [752 / 1200] average loss: 6.306808\n",
      "Epoch [752 / 1200] test loss: 6.327845\n",
      "Epoch [753 / 1200] average loss: 6.336710\n",
      "Epoch [753 / 1200] test loss: 6.338736\n",
      "Epoch [754 / 1200] average loss: 6.268615\n",
      "Epoch [754 / 1200] test loss: 6.387060\n",
      "Epoch [755 / 1200] average loss: 6.313928\n",
      "Epoch [755 / 1200] test loss: 6.526678\n",
      "Epoch [756 / 1200] average loss: 6.331869\n",
      "Epoch [756 / 1200] test loss: 6.480349\n",
      "Epoch [757 / 1200] average loss: 6.407717\n",
      "Epoch [757 / 1200] test loss: 6.432285\n",
      "Epoch [758 / 1200] average loss: 6.528126\n",
      "Epoch [758 / 1200] test loss: 6.489179\n",
      "Epoch [759 / 1200] average loss: 6.608411\n",
      "Epoch [759 / 1200] test loss: 6.361346\n",
      "Epoch [760 / 1200] average loss: 6.316523\n",
      "Epoch [760 / 1200] test loss: 6.383020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [761 / 1200] average loss: 6.563370\n",
      "Epoch [761 / 1200] test loss: 6.226520\n",
      "Epoch [762 / 1200] average loss: 6.285786\n",
      "Epoch [762 / 1200] test loss: 6.412301\n",
      "Epoch [763 / 1200] average loss: 6.267146\n",
      "Epoch [763 / 1200] test loss: 6.330948\n",
      "Epoch [764 / 1200] average loss: 6.270937\n",
      "Epoch [764 / 1200] test loss: 6.490576\n",
      "Epoch [765 / 1200] average loss: 6.274732\n",
      "Epoch [765 / 1200] test loss: 6.295279\n",
      "Epoch [766 / 1200] average loss: 6.199009\n",
      "Epoch [766 / 1200] test loss: 6.374285\n",
      "Epoch [767 / 1200] average loss: 6.241603\n",
      "Epoch [767 / 1200] test loss: 6.308371\n",
      "Epoch [768 / 1200] average loss: 6.503535\n",
      "Epoch [768 / 1200] test loss: 6.263763\n",
      "Epoch [769 / 1200] average loss: 6.294704\n",
      "Epoch [769 / 1200] test loss: 6.516586\n",
      "Epoch [770 / 1200] average loss: 6.261077\n",
      "Epoch [770 / 1200] test loss: 6.514886\n",
      "Epoch [771 / 1200] average loss: 6.233511\n",
      "Epoch [771 / 1200] test loss: 6.266987\n",
      "Epoch [772 / 1200] average loss: 6.156487\n",
      "Epoch [772 / 1200] test loss: 6.206981\n",
      "Epoch [773 / 1200] average loss: 6.208873\n",
      "Epoch [773 / 1200] test loss: 6.307779\n",
      "Epoch [774 / 1200] average loss: 6.261339\n",
      "Epoch [774 / 1200] test loss: 6.337044\n",
      "Epoch [775 / 1200] average loss: 6.246684\n",
      "Epoch [775 / 1200] test loss: 6.304317\n",
      "Epoch [776 / 1200] average loss: 6.185438\n",
      "Epoch [776 / 1200] test loss: 6.253464\n",
      "Epoch [777 / 1200] average loss: 6.220341\n",
      "Epoch [777 / 1200] test loss: 6.126500\n",
      "Epoch [778 / 1200] average loss: 6.157207\n",
      "Epoch [778 / 1200] test loss: 6.284435\n",
      "Epoch [779 / 1200] average loss: 6.401558\n",
      "Epoch [779 / 1200] test loss: 6.160645\n",
      "Epoch [780 / 1200] average loss: 6.309586\n",
      "Epoch [780 / 1200] test loss: 6.263386\n",
      "Epoch [781 / 1200] average loss: 6.403883\n",
      "Epoch [781 / 1200] test loss: 6.364236\n",
      "Epoch [782 / 1200] average loss: 6.283779\n",
      "Epoch [782 / 1200] test loss: 6.361057\n",
      "Epoch [783 / 1200] average loss: 6.275537\n",
      "Epoch [783 / 1200] test loss: 6.078004\n",
      "Epoch [784 / 1200] average loss: 6.410039\n",
      "Epoch [784 / 1200] test loss: 6.639633\n",
      "Epoch [785 / 1200] average loss: 6.222773\n",
      "Epoch [785 / 1200] test loss: 6.182228\n",
      "Epoch [786 / 1200] average loss: 6.258986\n",
      "Epoch [786 / 1200] test loss: 6.432876\n",
      "Epoch [787 / 1200] average loss: 6.171847\n",
      "Epoch [787 / 1200] test loss: 6.286129\n",
      "Epoch [788 / 1200] average loss: 6.258765\n",
      "Epoch [788 / 1200] test loss: 6.359645\n",
      "Epoch [789 / 1200] average loss: 6.254848\n",
      "Epoch [789 / 1200] test loss: 6.424845\n",
      "Epoch [790 / 1200] average loss: 6.170918\n",
      "Epoch [790 / 1200] test loss: 6.291338\n",
      "Epoch [791 / 1200] average loss: 6.234177\n",
      "Epoch [791 / 1200] test loss: 6.239960\n",
      "Epoch [792 / 1200] average loss: 6.179027\n",
      "Epoch [792 / 1200] test loss: 6.293222\n",
      "Epoch [793 / 1200] average loss: 6.078183\n",
      "Epoch [793 / 1200] test loss: 6.081150\n",
      "Epoch [794 / 1200] average loss: 6.165390\n",
      "Epoch [794 / 1200] test loss: 6.123714\n",
      "Epoch [795 / 1200] average loss: 6.204440\n",
      "Epoch [795 / 1200] test loss: 6.062451\n",
      "Epoch [796 / 1200] average loss: 6.092085\n",
      "Epoch [796 / 1200] test loss: 6.084755\n",
      "Epoch [797 / 1200] average loss: 6.091229\n",
      "Epoch [797 / 1200] test loss: 6.146400\n",
      "Epoch [798 / 1200] average loss: 6.104196\n",
      "Epoch [798 / 1200] test loss: 6.146551\n",
      "Epoch [799 / 1200] average loss: 6.020649\n",
      "Epoch [799 / 1200] test loss: 6.263760\n",
      "Epoch [800 / 1200] average loss: 6.359497\n",
      "Epoch [800 / 1200] test loss: 6.449576\n",
      "Epoch [801 / 1200] average loss: 5.980507\n",
      "Epoch [801 / 1200] test loss: 6.204104\n",
      "Epoch [802 / 1200] average loss: 6.165413\n",
      "Epoch [802 / 1200] test loss: 6.104558\n",
      "Epoch [803 / 1200] average loss: 6.070673\n",
      "Epoch [803 / 1200] test loss: 6.177631\n",
      "Epoch [804 / 1200] average loss: 6.101999\n",
      "Epoch [804 / 1200] test loss: 6.235324\n",
      "Epoch [805 / 1200] average loss: 6.046429\n",
      "Epoch [805 / 1200] test loss: 6.284624\n",
      "Epoch [806 / 1200] average loss: 5.958123\n",
      "Epoch [806 / 1200] test loss: 6.358472\n",
      "Epoch [807 / 1200] average loss: 6.178153\n",
      "Epoch [807 / 1200] test loss: 6.234358\n",
      "Epoch [808 / 1200] average loss: 6.282859\n",
      "Epoch [808 / 1200] test loss: 6.393065\n",
      "Epoch [809 / 1200] average loss: 6.342858\n",
      "Epoch [809 / 1200] test loss: 7.130540\n",
      "Epoch [810 / 1200] average loss: 7.107134\n",
      "Epoch [810 / 1200] test loss: 9.121183\n",
      "Epoch [811 / 1200] average loss: 9.502489\n",
      "Epoch [811 / 1200] test loss: 7.734705\n",
      "Epoch [812 / 1200] average loss: 8.096400\n",
      "Epoch [812 / 1200] test loss: 7.797204\n",
      "Epoch [813 / 1200] average loss: 8.149322\n",
      "Epoch [813 / 1200] test loss: 6.715797\n",
      "Epoch [814 / 1200] average loss: 7.493447\n",
      "Epoch [814 / 1200] test loss: 6.211616\n",
      "Epoch [815 / 1200] average loss: 7.101944\n",
      "Epoch [815 / 1200] test loss: 7.114507\n",
      "Epoch [816 / 1200] average loss: 7.399705\n",
      "Epoch [816 / 1200] test loss: 6.315592\n",
      "Epoch [817 / 1200] average loss: 7.141530\n",
      "Epoch [817 / 1200] test loss: 6.639149\n",
      "Epoch [818 / 1200] average loss: 7.322140\n",
      "Epoch [818 / 1200] test loss: 6.283309\n",
      "Epoch [819 / 1200] average loss: 7.523898\n",
      "Epoch [819 / 1200] test loss: 6.429762\n",
      "Epoch [820 / 1200] average loss: 7.575909\n",
      "Epoch [820 / 1200] test loss: 6.308101\n",
      "Epoch [821 / 1200] average loss: 7.272756\n",
      "Epoch [821 / 1200] test loss: 6.757012\n",
      "Epoch [822 / 1200] average loss: 7.080588\n",
      "Epoch [822 / 1200] test loss: 7.003164\n",
      "Epoch [823 / 1200] average loss: 6.716349\n",
      "Epoch [823 / 1200] test loss: 6.673679\n",
      "Epoch [824 / 1200] average loss: 6.638259\n",
      "Epoch [824 / 1200] test loss: 6.349844\n",
      "Epoch [825 / 1200] average loss: 6.566864\n",
      "Epoch [825 / 1200] test loss: 6.433811\n",
      "Epoch [826 / 1200] average loss: 6.515937\n",
      "Epoch [826 / 1200] test loss: 6.389339\n",
      "Epoch [827 / 1200] average loss: 6.395275\n",
      "Epoch [827 / 1200] test loss: 6.461704\n",
      "Epoch [828 / 1200] average loss: 6.351856\n",
      "Epoch [828 / 1200] test loss: 6.277614\n",
      "Epoch [829 / 1200] average loss: 6.372849\n",
      "Epoch [829 / 1200] test loss: 6.419761\n",
      "Epoch [830 / 1200] average loss: 6.231872\n",
      "Epoch [830 / 1200] test loss: 6.424726\n",
      "Epoch [831 / 1200] average loss: 6.312809\n",
      "Epoch [831 / 1200] test loss: 6.357911\n",
      "Epoch [832 / 1200] average loss: 6.424540\n",
      "Epoch [832 / 1200] test loss: 6.505213\n",
      "Epoch [833 / 1200] average loss: 6.274168\n",
      "Epoch [833 / 1200] test loss: 6.453527\n",
      "Epoch [834 / 1200] average loss: 6.242361\n",
      "Epoch [834 / 1200] test loss: 6.472303\n",
      "Epoch [835 / 1200] average loss: 6.181971\n",
      "Epoch [835 / 1200] test loss: 6.391696\n",
      "Epoch [836 / 1200] average loss: 6.189378\n",
      "Epoch [836 / 1200] test loss: 6.194504\n",
      "Epoch [837 / 1200] average loss: 6.362649\n",
      "Epoch [837 / 1200] test loss: 6.410050\n",
      "Epoch [838 / 1200] average loss: 6.254818\n",
      "Epoch [838 / 1200] test loss: 6.382743\n",
      "Epoch [839 / 1200] average loss: 6.227891\n",
      "Epoch [839 / 1200] test loss: 6.238939\n",
      "Epoch [840 / 1200] average loss: 6.181056\n",
      "Epoch [840 / 1200] test loss: 6.401517\n",
      "Epoch [841 / 1200] average loss: 6.251748\n",
      "Epoch [841 / 1200] test loss: 6.248038\n",
      "Epoch [842 / 1200] average loss: 6.172426\n",
      "Epoch [842 / 1200] test loss: 6.336158\n",
      "Epoch [843 / 1200] average loss: 6.128768\n",
      "Epoch [843 / 1200] test loss: 6.301230\n",
      "Epoch [844 / 1200] average loss: 6.267146\n",
      "Epoch [844 / 1200] test loss: 6.297371\n",
      "Epoch [845 / 1200] average loss: 6.200102\n",
      "Epoch [845 / 1200] test loss: 6.256172\n",
      "Epoch [846 / 1200] average loss: 6.107872\n",
      "Epoch [846 / 1200] test loss: 6.339971\n",
      "Epoch [847 / 1200] average loss: 6.000663\n",
      "Epoch [847 / 1200] test loss: 6.287049\n",
      "Epoch [848 / 1200] average loss: 6.197250\n",
      "Epoch [848 / 1200] test loss: 6.427056\n",
      "Epoch [849 / 1200] average loss: 6.126541\n",
      "Epoch [849 / 1200] test loss: 6.281410\n",
      "Epoch [850 / 1200] average loss: 6.160459\n",
      "Epoch [850 / 1200] test loss: 6.427531\n",
      "Epoch [851 / 1200] average loss: 6.148561\n",
      "Epoch [851 / 1200] test loss: 6.411516\n",
      "Epoch [852 / 1200] average loss: 6.125473\n",
      "Epoch [852 / 1200] test loss: 6.438319\n",
      "Epoch [853 / 1200] average loss: 6.195557\n",
      "Epoch [853 / 1200] test loss: 6.291101\n",
      "Epoch [854 / 1200] average loss: 6.181590\n",
      "Epoch [854 / 1200] test loss: 6.266805\n",
      "Epoch [855 / 1200] average loss: 6.135835\n",
      "Epoch [855 / 1200] test loss: 6.118136\n",
      "Epoch [856 / 1200] average loss: 6.314652\n",
      "Epoch [856 / 1200] test loss: 6.257605\n",
      "Epoch [857 / 1200] average loss: 6.361792\n",
      "Epoch [857 / 1200] test loss: 6.123194\n",
      "Epoch [858 / 1200] average loss: 6.240076\n",
      "Epoch [858 / 1200] test loss: 6.432546\n",
      "Epoch [859 / 1200] average loss: 6.264267\n",
      "Epoch [859 / 1200] test loss: 6.283508\n",
      "Epoch [860 / 1200] average loss: 6.739893\n",
      "Epoch [860 / 1200] test loss: 6.388545\n",
      "Epoch [861 / 1200] average loss: 6.501234\n",
      "Epoch [861 / 1200] test loss: 6.560224\n",
      "Epoch [862 / 1200] average loss: 6.519064\n",
      "Epoch [862 / 1200] test loss: 6.403789\n",
      "Epoch [863 / 1200] average loss: 6.175553\n",
      "Epoch [863 / 1200] test loss: 6.606452\n",
      "Epoch [864 / 1200] average loss: 6.279965\n",
      "Epoch [864 / 1200] test loss: 6.335004\n",
      "Epoch [865 / 1200] average loss: 6.244769\n",
      "Epoch [865 / 1200] test loss: 6.394620\n",
      "Epoch [866 / 1200] average loss: 6.477081\n",
      "Epoch [866 / 1200] test loss: 6.539202\n",
      "Epoch [867 / 1200] average loss: 6.134612\n",
      "Epoch [867 / 1200] test loss: 6.372728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [868 / 1200] average loss: 6.165430\n",
      "Epoch [868 / 1200] test loss: 6.141957\n",
      "Epoch [869 / 1200] average loss: 6.093778\n",
      "Epoch [869 / 1200] test loss: 6.472972\n",
      "Epoch [870 / 1200] average loss: 6.123723\n",
      "Epoch [870 / 1200] test loss: 6.373996\n",
      "Epoch [871 / 1200] average loss: 6.141636\n",
      "Epoch [871 / 1200] test loss: 6.203817\n",
      "Epoch [872 / 1200] average loss: 6.083441\n",
      "Epoch [872 / 1200] test loss: 6.340597\n",
      "Epoch [873 / 1200] average loss: 6.221851\n",
      "Epoch [873 / 1200] test loss: 6.319211\n",
      "Epoch [874 / 1200] average loss: 6.082011\n",
      "Epoch [874 / 1200] test loss: 6.281639\n",
      "Epoch [875 / 1200] average loss: 6.075092\n",
      "Epoch [875 / 1200] test loss: 6.274200\n",
      "Epoch [876 / 1200] average loss: 6.208860\n",
      "Epoch [876 / 1200] test loss: 6.280231\n",
      "Epoch [877 / 1200] average loss: 6.063308\n",
      "Epoch [877 / 1200] test loss: 6.048145\n",
      "Epoch [878 / 1200] average loss: 6.114619\n",
      "Epoch [878 / 1200] test loss: 6.620199\n",
      "Epoch [879 / 1200] average loss: 6.156763\n",
      "Epoch [879 / 1200] test loss: 6.210804\n",
      "Epoch [880 / 1200] average loss: 6.081514\n",
      "Epoch [880 / 1200] test loss: 6.244586\n",
      "Epoch [881 / 1200] average loss: 6.190227\n",
      "Epoch [881 / 1200] test loss: 6.362597\n",
      "Epoch [882 / 1200] average loss: 6.061408\n",
      "Epoch [882 / 1200] test loss: 6.181372\n",
      "Epoch [883 / 1200] average loss: 6.180115\n",
      "Epoch [883 / 1200] test loss: 6.057754\n",
      "Epoch [884 / 1200] average loss: 6.057719\n",
      "Epoch [884 / 1200] test loss: 6.134635\n",
      "Epoch [885 / 1200] average loss: 6.238332\n",
      "Epoch [885 / 1200] test loss: 6.082947\n",
      "Epoch [886 / 1200] average loss: 6.151924\n",
      "Epoch [886 / 1200] test loss: 6.202000\n",
      "Epoch [887 / 1200] average loss: 6.099606\n",
      "Epoch [887 / 1200] test loss: 6.224137\n",
      "Epoch [888 / 1200] average loss: 5.972159\n",
      "Epoch [888 / 1200] test loss: 6.138104\n",
      "Epoch [889 / 1200] average loss: 6.169554\n",
      "Epoch [889 / 1200] test loss: 6.233018\n",
      "Epoch [890 / 1200] average loss: 6.007712\n",
      "Epoch [890 / 1200] test loss: 6.248757\n",
      "Epoch [891 / 1200] average loss: 6.024802\n",
      "Epoch [891 / 1200] test loss: 6.347735\n",
      "Epoch [892 / 1200] average loss: 6.132063\n",
      "Epoch [892 / 1200] test loss: 6.031086\n",
      "Epoch [893 / 1200] average loss: 6.181059\n",
      "Epoch [893 / 1200] test loss: 6.214718\n",
      "Epoch [894 / 1200] average loss: 6.139682\n",
      "Epoch [894 / 1200] test loss: 6.202461\n",
      "Epoch [895 / 1200] average loss: 6.005142\n",
      "Epoch [895 / 1200] test loss: 6.277262\n",
      "Epoch [896 / 1200] average loss: 6.007227\n",
      "Epoch [896 / 1200] test loss: 6.253670\n",
      "Epoch [897 / 1200] average loss: 5.956234\n",
      "Epoch [897 / 1200] test loss: 6.188848\n",
      "Epoch [898 / 1200] average loss: 6.012372\n",
      "Epoch [898 / 1200] test loss: 6.057438\n",
      "Epoch [899 / 1200] average loss: 5.964494\n",
      "Epoch [899 / 1200] test loss: 6.089918\n",
      "Epoch [900 / 1200] average loss: 6.133019\n",
      "Epoch [900 / 1200] test loss: 6.081629\n",
      "Epoch [901 / 1200] average loss: 5.951158\n",
      "Epoch [901 / 1200] test loss: 6.036715\n",
      "Epoch [902 / 1200] average loss: 5.900461\n",
      "Epoch [902 / 1200] test loss: 5.939925\n",
      "Epoch [903 / 1200] average loss: 5.960484\n",
      "Epoch [903 / 1200] test loss: 6.217000\n",
      "Epoch [904 / 1200] average loss: 5.840250\n",
      "Epoch [904 / 1200] test loss: 6.180069\n",
      "Epoch [905 / 1200] average loss: 6.054630\n",
      "Epoch [905 / 1200] test loss: 6.073328\n",
      "Epoch [906 / 1200] average loss: 5.917086\n",
      "Epoch [906 / 1200] test loss: 6.100992\n",
      "Epoch [907 / 1200] average loss: 5.927070\n",
      "Epoch [907 / 1200] test loss: 6.128236\n",
      "Epoch [908 / 1200] average loss: 5.969519\n",
      "Epoch [908 / 1200] test loss: 6.064528\n",
      "Epoch [909 / 1200] average loss: 5.908646\n",
      "Epoch [909 / 1200] test loss: 6.087050\n",
      "Epoch [910 / 1200] average loss: 5.968297\n",
      "Epoch [910 / 1200] test loss: 6.172313\n",
      "Epoch [911 / 1200] average loss: 5.884512\n",
      "Epoch [911 / 1200] test loss: 6.359874\n",
      "Epoch [912 / 1200] average loss: 5.956811\n",
      "Epoch [912 / 1200] test loss: 6.267373\n",
      "Epoch [913 / 1200] average loss: 5.935861\n",
      "Epoch [913 / 1200] test loss: 6.005517\n",
      "Epoch [914 / 1200] average loss: 5.943779\n",
      "Epoch [914 / 1200] test loss: 6.136787\n",
      "Epoch [915 / 1200] average loss: 6.124675\n",
      "Epoch [915 / 1200] test loss: 6.091828\n",
      "Epoch [916 / 1200] average loss: 6.006877\n",
      "Epoch [916 / 1200] test loss: 6.114111\n",
      "Epoch [917 / 1200] average loss: 6.090838\n",
      "Epoch [917 / 1200] test loss: 6.106100\n",
      "Epoch [918 / 1200] average loss: 6.071391\n",
      "Epoch [918 / 1200] test loss: 6.062404\n",
      "Epoch [919 / 1200] average loss: 6.070907\n",
      "Epoch [919 / 1200] test loss: 5.958037\n",
      "Epoch [920 / 1200] average loss: 6.042945\n",
      "Epoch [920 / 1200] test loss: 5.999774\n",
      "Epoch [921 / 1200] average loss: 6.121569\n",
      "Epoch [921 / 1200] test loss: 6.152240\n",
      "Epoch [922 / 1200] average loss: 6.092897\n",
      "Epoch [922 / 1200] test loss: 6.125086\n",
      "Epoch [923 / 1200] average loss: 6.258226\n",
      "Epoch [923 / 1200] test loss: 5.916141\n",
      "Epoch [924 / 1200] average loss: 5.984049\n",
      "Epoch [924 / 1200] test loss: 6.394939\n",
      "Epoch [925 / 1200] average loss: 6.155827\n",
      "Epoch [925 / 1200] test loss: 6.048248\n",
      "Epoch [926 / 1200] average loss: 6.216543\n",
      "Epoch [926 / 1200] test loss: 6.280123\n",
      "Epoch [927 / 1200] average loss: 6.094781\n",
      "Epoch [927 / 1200] test loss: 6.227096\n",
      "Epoch [928 / 1200] average loss: 5.884192\n",
      "Epoch [928 / 1200] test loss: 5.987784\n",
      "Epoch [929 / 1200] average loss: 5.988695\n",
      "Epoch [929 / 1200] test loss: 6.083827\n",
      "Epoch [930 / 1200] average loss: 5.807052\n",
      "Epoch [930 / 1200] test loss: 6.114437\n",
      "Epoch [931 / 1200] average loss: 5.866793\n",
      "Epoch [931 / 1200] test loss: 5.921516\n",
      "Epoch [932 / 1200] average loss: 5.939514\n",
      "Epoch [932 / 1200] test loss: 6.006659\n",
      "Epoch [933 / 1200] average loss: 5.853999\n",
      "Epoch [933 / 1200] test loss: 6.079467\n",
      "Epoch [934 / 1200] average loss: 5.947770\n",
      "Epoch [934 / 1200] test loss: 6.097585\n",
      "Epoch [935 / 1200] average loss: 6.026016\n",
      "Epoch [935 / 1200] test loss: 6.057600\n",
      "Epoch [936 / 1200] average loss: 5.911049\n",
      "Epoch [936 / 1200] test loss: 6.059044\n",
      "Epoch [937 / 1200] average loss: 5.914287\n",
      "Epoch [937 / 1200] test loss: 6.041804\n",
      "Epoch [938 / 1200] average loss: 5.942604\n",
      "Epoch [938 / 1200] test loss: 6.078479\n",
      "Epoch [939 / 1200] average loss: 5.877325\n",
      "Epoch [939 / 1200] test loss: 5.981505\n",
      "Epoch [940 / 1200] average loss: 5.814645\n",
      "Epoch [940 / 1200] test loss: 6.012049\n",
      "Epoch [941 / 1200] average loss: 5.839203\n",
      "Epoch [941 / 1200] test loss: 6.065381\n",
      "Epoch [942 / 1200] average loss: 5.851770\n",
      "Epoch [942 / 1200] test loss: 5.984148\n",
      "Epoch [943 / 1200] average loss: 6.036878\n",
      "Epoch [943 / 1200] test loss: 6.061559\n",
      "Epoch [944 / 1200] average loss: 5.878788\n",
      "Epoch [944 / 1200] test loss: 6.017166\n",
      "Epoch [945 / 1200] average loss: 5.810803\n",
      "Epoch [945 / 1200] test loss: 6.077027\n",
      "Epoch [946 / 1200] average loss: 5.841565\n",
      "Epoch [946 / 1200] test loss: 5.905626\n",
      "Epoch [947 / 1200] average loss: 5.813993\n",
      "Epoch [947 / 1200] test loss: 5.894828\n",
      "Epoch [948 / 1200] average loss: 5.897221\n",
      "Epoch [948 / 1200] test loss: 6.062508\n",
      "Epoch [949 / 1200] average loss: 5.993364\n",
      "Epoch [949 / 1200] test loss: 6.144941\n",
      "Epoch [950 / 1200] average loss: 5.874086\n",
      "Epoch [950 / 1200] test loss: 6.089028\n",
      "Epoch [951 / 1200] average loss: 5.828542\n",
      "Epoch [951 / 1200] test loss: 6.274868\n",
      "Epoch [952 / 1200] average loss: 5.901928\n",
      "Epoch [952 / 1200] test loss: 6.040408\n",
      "Epoch [953 / 1200] average loss: 5.926378\n",
      "Epoch [953 / 1200] test loss: 6.343575\n",
      "Epoch [954 / 1200] average loss: 6.170917\n",
      "Epoch [954 / 1200] test loss: 6.802741\n",
      "Epoch [955 / 1200] average loss: 6.850484\n",
      "Epoch [955 / 1200] test loss: 7.639407\n",
      "Epoch [956 / 1200] average loss: 7.537386\n",
      "Epoch [956 / 1200] test loss: 6.543352\n",
      "Epoch [957 / 1200] average loss: 6.401846\n",
      "Epoch [957 / 1200] test loss: 6.606257\n",
      "Epoch [958 / 1200] average loss: 6.507961\n",
      "Epoch [958 / 1200] test loss: 6.645560\n",
      "Epoch [959 / 1200] average loss: 6.260907\n",
      "Epoch [959 / 1200] test loss: 6.363597\n",
      "Epoch [960 / 1200] average loss: 6.278981\n",
      "Epoch [960 / 1200] test loss: 6.183923\n",
      "Epoch [961 / 1200] average loss: 6.024991\n",
      "Epoch [961 / 1200] test loss: 6.283839\n",
      "Epoch [962 / 1200] average loss: 6.138255\n",
      "Epoch [962 / 1200] test loss: 5.860749\n",
      "Epoch [963 / 1200] average loss: 5.996358\n",
      "Epoch [963 / 1200] test loss: 6.170400\n",
      "Epoch [964 / 1200] average loss: 5.873065\n",
      "Epoch [964 / 1200] test loss: 6.156434\n",
      "Epoch [965 / 1200] average loss: 5.934558\n",
      "Epoch [965 / 1200] test loss: 5.960636\n",
      "Epoch [966 / 1200] average loss: 6.060929\n",
      "Epoch [966 / 1200] test loss: 5.880605\n",
      "Epoch [967 / 1200] average loss: 6.088838\n",
      "Epoch [967 / 1200] test loss: 6.189801\n",
      "Epoch [968 / 1200] average loss: 6.040204\n",
      "Epoch [968 / 1200] test loss: 6.114875\n",
      "Epoch [969 / 1200] average loss: 5.930102\n",
      "Epoch [969 / 1200] test loss: 6.320089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [970 / 1200] average loss: 6.162514\n",
      "Epoch [970 / 1200] test loss: 6.172233\n",
      "Epoch [971 / 1200] average loss: 6.013788\n",
      "Epoch [971 / 1200] test loss: 6.174318\n",
      "Epoch [972 / 1200] average loss: 6.092151\n",
      "Epoch [972 / 1200] test loss: 5.774138\n",
      "Epoch [973 / 1200] average loss: 5.912786\n",
      "Epoch [973 / 1200] test loss: 6.170780\n",
      "Epoch [974 / 1200] average loss: 6.022034\n",
      "Epoch [974 / 1200] test loss: 6.154656\n",
      "Epoch [975 / 1200] average loss: 5.759540\n",
      "Epoch [975 / 1200] test loss: 5.994872\n",
      "Epoch [976 / 1200] average loss: 5.868190\n",
      "Epoch [976 / 1200] test loss: 6.039385\n",
      "Epoch [977 / 1200] average loss: 5.869390\n",
      "Epoch [977 / 1200] test loss: 6.287345\n",
      "Epoch [978 / 1200] average loss: 5.799627\n",
      "Epoch [978 / 1200] test loss: 6.127980\n",
      "Epoch [979 / 1200] average loss: 5.835467\n",
      "Epoch [979 / 1200] test loss: 6.056859\n",
      "Epoch [980 / 1200] average loss: 5.799015\n",
      "Epoch [980 / 1200] test loss: 6.039463\n",
      "Epoch [981 / 1200] average loss: 5.952573\n",
      "Epoch [981 / 1200] test loss: 6.003320\n",
      "Epoch [982 / 1200] average loss: 5.781170\n",
      "Epoch [982 / 1200] test loss: 5.799038\n",
      "Epoch [983 / 1200] average loss: 5.883319\n",
      "Epoch [983 / 1200] test loss: 6.014861\n",
      "Epoch [984 / 1200] average loss: 5.740136\n",
      "Epoch [984 / 1200] test loss: 5.837251\n",
      "Epoch [985 / 1200] average loss: 5.794347\n",
      "Epoch [985 / 1200] test loss: 5.897085\n",
      "Epoch [986 / 1200] average loss: 5.721246\n",
      "Epoch [986 / 1200] test loss: 6.160907\n",
      "Epoch [987 / 1200] average loss: 5.894738\n",
      "Epoch [987 / 1200] test loss: 5.862139\n",
      "Epoch [988 / 1200] average loss: 5.785608\n",
      "Epoch [988 / 1200] test loss: 5.901950\n",
      "Epoch [989 / 1200] average loss: 5.835727\n",
      "Epoch [989 / 1200] test loss: 6.108292\n",
      "Epoch [990 / 1200] average loss: 5.739655\n",
      "Epoch [990 / 1200] test loss: 5.893074\n",
      "Epoch [991 / 1200] average loss: 5.855694\n",
      "Epoch [991 / 1200] test loss: 5.938029\n",
      "Epoch [992 / 1200] average loss: 5.699399\n",
      "Epoch [992 / 1200] test loss: 6.061392\n",
      "Epoch [993 / 1200] average loss: 5.756972\n",
      "Epoch [993 / 1200] test loss: 5.920510\n",
      "Epoch [994 / 1200] average loss: 5.723157\n",
      "Epoch [994 / 1200] test loss: 6.026554\n",
      "Epoch [995 / 1200] average loss: 5.751434\n",
      "Epoch [995 / 1200] test loss: 5.958067\n",
      "Epoch [996 / 1200] average loss: 5.772058\n",
      "Epoch [996 / 1200] test loss: 5.949976\n",
      "Epoch [997 / 1200] average loss: 5.837901\n",
      "Epoch [997 / 1200] test loss: 6.242237\n",
      "Epoch [998 / 1200] average loss: 5.853832\n",
      "Epoch [998 / 1200] test loss: 5.918473\n",
      "Epoch [999 / 1200] average loss: 5.932648\n",
      "Epoch [999 / 1200] test loss: 5.817327\n",
      "Epoch [1000 / 1200] average loss: 5.832408\n",
      "Epoch [1000 / 1200] test loss: 5.982211\n",
      "Epoch [1001 / 1200] average loss: 6.094751\n",
      "Epoch [1001 / 1200] test loss: 5.880571\n",
      "Epoch [1002 / 1200] average loss: 5.981306\n",
      "Epoch [1002 / 1200] test loss: 6.038422\n",
      "Epoch [1003 / 1200] average loss: 6.206327\n",
      "Epoch [1003 / 1200] test loss: 5.905071\n",
      "Epoch [1004 / 1200] average loss: 5.975358\n",
      "Epoch [1004 / 1200] test loss: 6.181061\n",
      "Epoch [1005 / 1200] average loss: 5.851601\n",
      "Epoch [1005 / 1200] test loss: 5.899682\n",
      "Epoch [1006 / 1200] average loss: 5.831593\n",
      "Epoch [1006 / 1200] test loss: 6.306751\n",
      "Epoch [1007 / 1200] average loss: 5.921065\n",
      "Epoch [1007 / 1200] test loss: 6.083045\n",
      "Epoch [1008 / 1200] average loss: 6.038185\n",
      "Epoch [1008 / 1200] test loss: 6.194363\n",
      "Epoch [1009 / 1200] average loss: 6.246294\n",
      "Epoch [1009 / 1200] test loss: 7.103695\n",
      "Epoch [1010 / 1200] average loss: 6.997566\n",
      "Epoch [1010 / 1200] test loss: 8.012513\n",
      "Epoch [1011 / 1200] average loss: 7.821799\n",
      "Epoch [1011 / 1200] test loss: 7.049740\n",
      "Epoch [1012 / 1200] average loss: 6.735700\n",
      "Epoch [1012 / 1200] test loss: 6.286126\n",
      "Epoch [1013 / 1200] average loss: 6.504818\n",
      "Epoch [1013 / 1200] test loss: 6.525493\n",
      "Epoch [1014 / 1200] average loss: 6.230718\n",
      "Epoch [1014 / 1200] test loss: 6.431820\n",
      "Epoch [1015 / 1200] average loss: 6.114373\n",
      "Epoch [1015 / 1200] test loss: 6.020756\n",
      "Epoch [1016 / 1200] average loss: 5.871019\n",
      "Epoch [1016 / 1200] test loss: 5.916520\n",
      "Epoch [1017 / 1200] average loss: 5.922148\n",
      "Epoch [1017 / 1200] test loss: 5.934133\n",
      "Epoch [1018 / 1200] average loss: 5.817073\n",
      "Epoch [1018 / 1200] test loss: 5.858875\n",
      "Epoch [1019 / 1200] average loss: 5.804256\n",
      "Epoch [1019 / 1200] test loss: 5.928330\n",
      "Epoch [1020 / 1200] average loss: 5.779901\n",
      "Epoch [1020 / 1200] test loss: 5.768934\n",
      "Epoch [1021 / 1200] average loss: 5.747036\n",
      "Epoch [1021 / 1200] test loss: 5.997662\n",
      "Epoch [1022 / 1200] average loss: 5.817353\n",
      "Epoch [1022 / 1200] test loss: 5.911604\n",
      "Epoch [1023 / 1200] average loss: 5.760903\n",
      "Epoch [1023 / 1200] test loss: 5.867788\n",
      "Epoch [1024 / 1200] average loss: 5.813203\n",
      "Epoch [1024 / 1200] test loss: 5.885250\n",
      "Epoch [1025 / 1200] average loss: 5.710021\n",
      "Epoch [1025 / 1200] test loss: 5.934521\n",
      "Epoch [1026 / 1200] average loss: 5.883298\n",
      "Epoch [1026 / 1200] test loss: 5.952377\n",
      "Epoch [1027 / 1200] average loss: 5.811341\n",
      "Epoch [1027 / 1200] test loss: 5.742972\n",
      "Epoch [1028 / 1200] average loss: 5.668782\n",
      "Epoch [1028 / 1200] test loss: 5.838346\n",
      "Epoch [1029 / 1200] average loss: 5.595512\n",
      "Epoch [1029 / 1200] test loss: 6.038080\n",
      "Epoch [1030 / 1200] average loss: 5.765630\n",
      "Epoch [1030 / 1200] test loss: 5.907475\n",
      "Epoch [1031 / 1200] average loss: 5.936393\n",
      "Epoch [1031 / 1200] test loss: 6.075859\n",
      "Epoch [1032 / 1200] average loss: 5.731194\n",
      "Epoch [1032 / 1200] test loss: 6.055989\n",
      "Epoch [1033 / 1200] average loss: 5.794618\n",
      "Epoch [1033 / 1200] test loss: 6.232259\n",
      "Epoch [1034 / 1200] average loss: 5.870439\n",
      "Epoch [1034 / 1200] test loss: 6.146884\n",
      "Epoch [1035 / 1200] average loss: 5.874826\n",
      "Epoch [1035 / 1200] test loss: 6.104233\n",
      "Epoch [1036 / 1200] average loss: 5.775748\n",
      "Epoch [1036 / 1200] test loss: 5.973393\n",
      "Epoch [1037 / 1200] average loss: 5.797841\n",
      "Epoch [1037 / 1200] test loss: 6.032664\n",
      "Epoch [1038 / 1200] average loss: 5.831652\n",
      "Epoch [1038 / 1200] test loss: 5.852487\n",
      "Epoch [1039 / 1200] average loss: 5.777126\n",
      "Epoch [1039 / 1200] test loss: 6.076431\n",
      "Epoch [1040 / 1200] average loss: 5.636315\n",
      "Epoch [1040 / 1200] test loss: 6.118020\n",
      "Epoch [1041 / 1200] average loss: 5.778849\n",
      "Epoch [1041 / 1200] test loss: 5.960405\n",
      "Epoch [1042 / 1200] average loss: 5.855520\n",
      "Epoch [1042 / 1200] test loss: 6.149231\n",
      "Epoch [1043 / 1200] average loss: 5.952867\n",
      "Epoch [1043 / 1200] test loss: 5.838945\n",
      "Epoch [1044 / 1200] average loss: 5.913413\n",
      "Epoch [1044 / 1200] test loss: 5.841236\n",
      "Epoch [1045 / 1200] average loss: 6.042226\n",
      "Epoch [1045 / 1200] test loss: 5.991066\n",
      "Epoch [1046 / 1200] average loss: 6.047713\n",
      "Epoch [1046 / 1200] test loss: 5.949290\n",
      "Epoch [1047 / 1200] average loss: 6.200364\n",
      "Epoch [1047 / 1200] test loss: 5.794750\n",
      "Epoch [1048 / 1200] average loss: 5.955585\n",
      "Epoch [1048 / 1200] test loss: 6.014051\n",
      "Epoch [1049 / 1200] average loss: 6.238916\n",
      "Epoch [1049 / 1200] test loss: 5.854792\n",
      "Epoch [1050 / 1200] average loss: 5.877702\n",
      "Epoch [1050 / 1200] test loss: 6.334690\n",
      "Epoch [1051 / 1200] average loss: 5.879896\n",
      "Epoch [1051 / 1200] test loss: 5.978505\n",
      "Epoch [1052 / 1200] average loss: 5.731365\n",
      "Epoch [1052 / 1200] test loss: 5.988740\n",
      "Epoch [1053 / 1200] average loss: 5.709132\n",
      "Epoch [1053 / 1200] test loss: 5.760387\n",
      "Epoch [1054 / 1200] average loss: 5.708224\n",
      "Epoch [1054 / 1200] test loss: 5.750022\n",
      "Epoch [1055 / 1200] average loss: 5.682984\n",
      "Epoch [1055 / 1200] test loss: 5.893108\n",
      "Epoch [1056 / 1200] average loss: 5.811849\n",
      "Epoch [1056 / 1200] test loss: 5.783288\n",
      "Epoch [1057 / 1200] average loss: 5.734243\n",
      "Epoch [1057 / 1200] test loss: 5.735042\n",
      "Epoch [1058 / 1200] average loss: 5.659940\n",
      "Epoch [1058 / 1200] test loss: 5.884496\n",
      "Epoch [1059 / 1200] average loss: 5.785618\n",
      "Epoch [1059 / 1200] test loss: 5.870383\n",
      "Epoch [1060 / 1200] average loss: 5.676947\n",
      "Epoch [1060 / 1200] test loss: 5.729211\n",
      "Epoch [1061 / 1200] average loss: 5.671233\n",
      "Epoch [1061 / 1200] test loss: 5.860909\n",
      "Epoch [1062 / 1200] average loss: 5.747995\n",
      "Epoch [1062 / 1200] test loss: 5.898660\n",
      "Epoch [1063 / 1200] average loss: 5.754445\n",
      "Epoch [1063 / 1200] test loss: 5.797285\n",
      "Epoch [1064 / 1200] average loss: 5.667932\n",
      "Epoch [1064 / 1200] test loss: 6.076511\n",
      "Epoch [1065 / 1200] average loss: 5.969799\n",
      "Epoch [1065 / 1200] test loss: 6.395471\n",
      "Epoch [1066 / 1200] average loss: 6.135729\n",
      "Epoch [1066 / 1200] test loss: 6.948930\n",
      "Epoch [1067 / 1200] average loss: 6.701364\n",
      "Epoch [1067 / 1200] test loss: 7.420655\n",
      "Epoch [1068 / 1200] average loss: 7.011926\n",
      "Epoch [1068 / 1200] test loss: 6.324817\n",
      "Epoch [1069 / 1200] average loss: 6.049240\n",
      "Epoch [1069 / 1200] test loss: 6.489297\n",
      "Epoch [1070 / 1200] average loss: 6.411110\n",
      "Epoch [1070 / 1200] test loss: 6.635404\n",
      "Epoch [1071 / 1200] average loss: 6.280045\n",
      "Epoch [1071 / 1200] test loss: 5.926567\n",
      "Epoch [1072 / 1200] average loss: 6.009159\n",
      "Epoch [1072 / 1200] test loss: 6.090102\n",
      "Epoch [1073 / 1200] average loss: 5.779684\n",
      "Epoch [1073 / 1200] test loss: 5.840547\n",
      "Epoch [1074 / 1200] average loss: 5.786091\n",
      "Epoch [1074 / 1200] test loss: 5.980528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1075 / 1200] average loss: 5.781813\n",
      "Epoch [1075 / 1200] test loss: 6.066668\n",
      "Epoch [1076 / 1200] average loss: 5.823567\n",
      "Epoch [1076 / 1200] test loss: 5.723870\n",
      "Epoch [1077 / 1200] average loss: 5.625996\n",
      "Epoch [1077 / 1200] test loss: 6.116089\n",
      "Epoch [1078 / 1200] average loss: 5.779135\n",
      "Epoch [1078 / 1200] test loss: 5.789840\n",
      "Epoch [1079 / 1200] average loss: 5.765366\n",
      "Epoch [1079 / 1200] test loss: 5.931943\n",
      "Epoch [1080 / 1200] average loss: 5.797360\n",
      "Epoch [1080 / 1200] test loss: 5.915856\n",
      "Epoch [1081 / 1200] average loss: 5.661688\n",
      "Epoch [1081 / 1200] test loss: 5.878162\n",
      "Epoch [1082 / 1200] average loss: 5.677624\n",
      "Epoch [1082 / 1200] test loss: 6.006619\n",
      "Epoch [1083 / 1200] average loss: 5.680047\n",
      "Epoch [1083 / 1200] test loss: 6.002596\n",
      "Epoch [1084 / 1200] average loss: 5.707266\n",
      "Epoch [1084 / 1200] test loss: 5.853659\n",
      "Epoch [1085 / 1200] average loss: 5.691774\n",
      "Epoch [1085 / 1200] test loss: 6.029968\n",
      "Epoch [1086 / 1200] average loss: 5.664143\n",
      "Epoch [1086 / 1200] test loss: 5.820618\n",
      "Epoch [1087 / 1200] average loss: 5.673898\n",
      "Epoch [1087 / 1200] test loss: 5.775394\n",
      "Epoch [1088 / 1200] average loss: 5.618610\n",
      "Epoch [1088 / 1200] test loss: 5.892981\n",
      "Epoch [1089 / 1200] average loss: 5.751980\n",
      "Epoch [1089 / 1200] test loss: 6.045058\n",
      "Epoch [1090 / 1200] average loss: 5.899810\n",
      "Epoch [1090 / 1200] test loss: 5.751699\n",
      "Epoch [1091 / 1200] average loss: 5.701939\n",
      "Epoch [1091 / 1200] test loss: 5.826569\n",
      "Epoch [1092 / 1200] average loss: 5.622780\n",
      "Epoch [1092 / 1200] test loss: 5.841900\n",
      "Epoch [1093 / 1200] average loss: 5.703098\n",
      "Epoch [1093 / 1200] test loss: 5.827411\n",
      "Epoch [1094 / 1200] average loss: 5.580041\n",
      "Epoch [1094 / 1200] test loss: 5.759032\n",
      "Epoch [1095 / 1200] average loss: 5.681450\n",
      "Epoch [1095 / 1200] test loss: 5.950508\n",
      "Epoch [1096 / 1200] average loss: 5.701792\n",
      "Epoch [1096 / 1200] test loss: 6.013582\n",
      "Epoch [1097 / 1200] average loss: 5.838588\n",
      "Epoch [1097 / 1200] test loss: 5.913373\n",
      "Epoch [1098 / 1200] average loss: 5.814121\n",
      "Epoch [1098 / 1200] test loss: 5.737830\n",
      "Epoch [1099 / 1200] average loss: 5.924254\n",
      "Epoch [1099 / 1200] test loss: 5.879246\n",
      "Epoch [1100 / 1200] average loss: 6.095255\n",
      "Epoch [1100 / 1200] test loss: 6.018580\n",
      "Epoch [1101 / 1200] average loss: 6.344284\n",
      "Epoch [1101 / 1200] test loss: 5.751830\n",
      "Epoch [1102 / 1200] average loss: 6.322255\n",
      "Epoch [1102 / 1200] test loss: 6.159724\n",
      "Epoch [1103 / 1200] average loss: 6.286739\n",
      "Epoch [1103 / 1200] test loss: 5.797729\n",
      "Epoch [1104 / 1200] average loss: 5.940635\n",
      "Epoch [1104 / 1200] test loss: 6.428452\n",
      "Epoch [1105 / 1200] average loss: 5.926499\n",
      "Epoch [1105 / 1200] test loss: 5.879497\n",
      "Epoch [1106 / 1200] average loss: 5.964720\n",
      "Epoch [1106 / 1200] test loss: 5.792545\n",
      "Epoch [1107 / 1200] average loss: 5.786451\n",
      "Epoch [1107 / 1200] test loss: 6.024572\n",
      "Epoch [1108 / 1200] average loss: 5.824999\n",
      "Epoch [1108 / 1200] test loss: 5.835766\n",
      "Epoch [1109 / 1200] average loss: 5.704157\n",
      "Epoch [1109 / 1200] test loss: 5.831493\n",
      "Epoch [1110 / 1200] average loss: 5.741980\n",
      "Epoch [1110 / 1200] test loss: 5.920071\n",
      "Epoch [1111 / 1200] average loss: 5.691310\n",
      "Epoch [1111 / 1200] test loss: 5.825207\n",
      "Epoch [1112 / 1200] average loss: 5.744604\n",
      "Epoch [1112 / 1200] test loss: 5.774440\n",
      "Epoch [1113 / 1200] average loss: 5.658861\n",
      "Epoch [1113 / 1200] test loss: 5.804552\n",
      "Epoch [1114 / 1200] average loss: 5.668433\n",
      "Epoch [1114 / 1200] test loss: 5.757396\n",
      "Epoch [1115 / 1200] average loss: 5.715929\n",
      "Epoch [1115 / 1200] test loss: 5.887175\n",
      "Epoch [1116 / 1200] average loss: 5.649383\n",
      "Epoch [1116 / 1200] test loss: 6.143822\n",
      "Epoch [1117 / 1200] average loss: 5.934227\n",
      "Epoch [1117 / 1200] test loss: 6.586559\n",
      "Epoch [1118 / 1200] average loss: 6.395507\n",
      "Epoch [1118 / 1200] test loss: 8.366631\n",
      "Epoch [1119 / 1200] average loss: 8.632039\n",
      "Epoch [1119 / 1200] test loss: 10.758413\n",
      "Epoch [1120 / 1200] average loss: 10.275846\n",
      "Epoch [1120 / 1200] test loss: 6.119827\n",
      "Epoch [1121 / 1200] average loss: 7.102884\n",
      "Epoch [1121 / 1200] test loss: 8.075021\n",
      "Epoch [1122 / 1200] average loss: 7.547403\n",
      "Epoch [1122 / 1200] test loss: 7.298640\n",
      "Epoch [1123 / 1200] average loss: 6.902243\n",
      "Epoch [1123 / 1200] test loss: 6.381935\n",
      "Epoch [1124 / 1200] average loss: 6.507240\n",
      "Epoch [1124 / 1200] test loss: 6.132528\n",
      "Epoch [1125 / 1200] average loss: 6.133201\n",
      "Epoch [1125 / 1200] test loss: 6.419730\n",
      "Epoch [1126 / 1200] average loss: 6.153269\n",
      "Epoch [1126 / 1200] test loss: 5.925706\n",
      "Epoch [1127 / 1200] average loss: 6.212729\n",
      "Epoch [1127 / 1200] test loss: 5.715424\n",
      "Epoch [1128 / 1200] average loss: 5.904549\n",
      "Epoch [1128 / 1200] test loss: 6.338109\n",
      "Epoch [1129 / 1200] average loss: 6.350998\n",
      "Epoch [1129 / 1200] test loss: 5.840303\n",
      "Epoch [1130 / 1200] average loss: 6.042679\n",
      "Epoch [1130 / 1200] test loss: 6.218595\n",
      "Epoch [1131 / 1200] average loss: 6.230236\n",
      "Epoch [1131 / 1200] test loss: 5.847258\n",
      "Epoch [1132 / 1200] average loss: 6.149466\n",
      "Epoch [1132 / 1200] test loss: 5.992964\n",
      "Epoch [1133 / 1200] average loss: 6.037649\n",
      "Epoch [1133 / 1200] test loss: 5.778797\n",
      "Epoch [1134 / 1200] average loss: 5.874466\n",
      "Epoch [1134 / 1200] test loss: 5.923362\n",
      "Epoch [1135 / 1200] average loss: 5.976228\n",
      "Epoch [1135 / 1200] test loss: 5.935867\n",
      "Epoch [1136 / 1200] average loss: 5.985698\n",
      "Epoch [1136 / 1200] test loss: 5.726897\n",
      "Epoch [1137 / 1200] average loss: 5.899554\n",
      "Epoch [1137 / 1200] test loss: 5.925596\n",
      "Epoch [1138 / 1200] average loss: 5.943527\n",
      "Epoch [1138 / 1200] test loss: 5.767068\n",
      "Epoch [1139 / 1200] average loss: 5.857241\n",
      "Epoch [1139 / 1200] test loss: 5.867037\n",
      "Epoch [1140 / 1200] average loss: 5.930931\n",
      "Epoch [1140 / 1200] test loss: 6.019121\n",
      "Epoch [1141 / 1200] average loss: 5.939322\n",
      "Epoch [1141 / 1200] test loss: 6.068032\n",
      "Epoch [1142 / 1200] average loss: 5.852014\n",
      "Epoch [1142 / 1200] test loss: 5.981213\n",
      "Epoch [1143 / 1200] average loss: 5.830000\n",
      "Epoch [1143 / 1200] test loss: 6.241650\n",
      "Epoch [1144 / 1200] average loss: 5.973728\n",
      "Epoch [1144 / 1200] test loss: 5.862511\n",
      "Epoch [1145 / 1200] average loss: 5.820667\n",
      "Epoch [1145 / 1200] test loss: 5.823461\n",
      "Epoch [1146 / 1200] average loss: 5.807512\n",
      "Epoch [1146 / 1200] test loss: 5.924290\n",
      "Epoch [1147 / 1200] average loss: 5.894803\n",
      "Epoch [1147 / 1200] test loss: 5.973879\n",
      "Epoch [1148 / 1200] average loss: 5.838428\n",
      "Epoch [1148 / 1200] test loss: 6.016200\n",
      "Epoch [1149 / 1200] average loss: 5.760360\n",
      "Epoch [1149 / 1200] test loss: 5.993893\n",
      "Epoch [1150 / 1200] average loss: 5.833122\n",
      "Epoch [1150 / 1200] test loss: 5.932783\n",
      "Epoch [1151 / 1200] average loss: 5.914361\n",
      "Epoch [1151 / 1200] test loss: 5.997049\n",
      "Epoch [1152 / 1200] average loss: 5.905071\n",
      "Epoch [1152 / 1200] test loss: 5.901560\n",
      "Epoch [1153 / 1200] average loss: 5.899156\n",
      "Epoch [1153 / 1200] test loss: 6.015216\n",
      "Epoch [1154 / 1200] average loss: 5.784903\n",
      "Epoch [1154 / 1200] test loss: 5.952851\n",
      "Epoch [1155 / 1200] average loss: 5.984093\n",
      "Epoch [1155 / 1200] test loss: 5.955570\n",
      "Epoch [1156 / 1200] average loss: 5.929033\n",
      "Epoch [1156 / 1200] test loss: 6.056027\n",
      "Epoch [1157 / 1200] average loss: 5.969844\n",
      "Epoch [1157 / 1200] test loss: 5.967914\n",
      "Epoch [1158 / 1200] average loss: 5.833251\n",
      "Epoch [1158 / 1200] test loss: 6.041015\n",
      "Epoch [1159 / 1200] average loss: 6.036483\n",
      "Epoch [1159 / 1200] test loss: 5.880519\n",
      "Epoch [1160 / 1200] average loss: 5.939587\n",
      "Epoch [1160 / 1200] test loss: 6.047171\n",
      "Epoch [1161 / 1200] average loss: 6.133077\n",
      "Epoch [1161 / 1200] test loss: 5.877238\n",
      "Epoch [1162 / 1200] average loss: 6.116598\n",
      "Epoch [1162 / 1200] test loss: 6.106384\n",
      "Epoch [1163 / 1200] average loss: 6.172000\n",
      "Epoch [1163 / 1200] test loss: 5.882006\n",
      "Epoch [1164 / 1200] average loss: 6.162987\n",
      "Epoch [1164 / 1200] test loss: 6.144542\n",
      "Epoch [1165 / 1200] average loss: 6.318780\n",
      "Epoch [1165 / 1200] test loss: 5.895072\n",
      "Epoch [1166 / 1200] average loss: 6.175405\n",
      "Epoch [1166 / 1200] test loss: 6.088962\n",
      "Epoch [1167 / 1200] average loss: 6.034025\n",
      "Epoch [1167 / 1200] test loss: 5.931504\n",
      "Epoch [1168 / 1200] average loss: 5.922983\n",
      "Epoch [1168 / 1200] test loss: 5.977693\n",
      "Epoch [1169 / 1200] average loss: 5.801739\n",
      "Epoch [1169 / 1200] test loss: 5.800347\n",
      "Epoch [1170 / 1200] average loss: 5.880230\n",
      "Epoch [1170 / 1200] test loss: 5.862181\n",
      "Epoch [1171 / 1200] average loss: 5.730855\n",
      "Epoch [1171 / 1200] test loss: 5.900319\n",
      "Epoch [1172 / 1200] average loss: 5.740399\n",
      "Epoch [1172 / 1200] test loss: 5.792113\n",
      "Epoch [1173 / 1200] average loss: 5.754627\n",
      "Epoch [1173 / 1200] test loss: 5.847417\n",
      "Epoch [1174 / 1200] average loss: 5.864955\n",
      "Epoch [1174 / 1200] test loss: 5.694301\n",
      "Epoch [1175 / 1200] average loss: 5.741611\n",
      "Epoch [1175 / 1200] test loss: 5.722515\n",
      "Epoch [1176 / 1200] average loss: 5.659004\n",
      "Epoch [1176 / 1200] test loss: 6.127500\n",
      "Epoch [1177 / 1200] average loss: 5.626237\n",
      "Epoch [1177 / 1200] test loss: 5.851836\n",
      "Epoch [1178 / 1200] average loss: 5.649404\n",
      "Epoch [1178 / 1200] test loss: 6.044581\n",
      "Epoch [1179 / 1200] average loss: 5.746161\n",
      "Epoch [1179 / 1200] test loss: 5.817303\n",
      "Epoch [1180 / 1200] average loss: 5.662461\n",
      "Epoch [1180 / 1200] test loss: 5.911813\n",
      "Epoch [1181 / 1200] average loss: 5.600483\n",
      "Epoch [1181 / 1200] test loss: 6.059882\n",
      "Epoch [1182 / 1200] average loss: 5.726807\n",
      "Epoch [1182 / 1200] test loss: 5.819301\n",
      "Epoch [1183 / 1200] average loss: 5.648748\n",
      "Epoch [1183 / 1200] test loss: 6.238085\n",
      "Epoch [1184 / 1200] average loss: 5.726874\n",
      "Epoch [1184 / 1200] test loss: 5.862664\n",
      "Epoch [1185 / 1200] average loss: 5.556676\n",
      "Epoch [1185 / 1200] test loss: 5.894049\n",
      "Epoch [1186 / 1200] average loss: 5.719585\n",
      "Epoch [1186 / 1200] test loss: 5.913746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1187 / 1200] average loss: 5.599201\n",
      "Epoch [1187 / 1200] test loss: 5.727123\n",
      "Epoch [1188 / 1200] average loss: 5.661499\n",
      "Epoch [1188 / 1200] test loss: 5.938106\n",
      "Epoch [1189 / 1200] average loss: 5.542627\n",
      "Epoch [1189 / 1200] test loss: 5.928069\n",
      "Epoch [1190 / 1200] average loss: 5.597591\n",
      "Epoch [1190 / 1200] test loss: 6.080123\n",
      "Epoch [1191 / 1200] average loss: 5.677589\n",
      "Epoch [1191 / 1200] test loss: 5.910114\n",
      "Epoch [1192 / 1200] average loss: 5.630794\n",
      "Epoch [1192 / 1200] test loss: 5.944467\n",
      "Epoch [1193 / 1200] average loss: 5.704642\n",
      "Epoch [1193 / 1200] test loss: 5.829081\n",
      "Epoch [1194 / 1200] average loss: 5.655841\n",
      "Epoch [1194 / 1200] test loss: 5.737768\n",
      "Epoch [1195 / 1200] average loss: 5.647693\n",
      "Epoch [1195 / 1200] test loss: 5.684508\n",
      "Epoch [1196 / 1200] average loss: 5.604398\n",
      "Epoch [1196 / 1200] test loss: 5.864296\n",
      "Epoch [1197 / 1200] average loss: 5.551797\n",
      "Epoch [1197 / 1200] test loss: 5.824958\n",
      "Epoch [1198 / 1200] average loss: 5.697881\n",
      "Epoch [1198 / 1200] test loss: 5.855811\n",
      "Epoch [1199 / 1200] average loss: 5.723857\n",
      "Epoch [1199 / 1200] test loss: 5.780179\n",
      "Epoch [1200 / 1200] average loss: 5.671017\n",
      "Epoch [1200 / 1200] test loss: 5.851365\n"
     ]
    }
   ],
   "source": [
    "train_loss_avg = []\n",
    "test_losses = []\n",
    "\n",
    "\n",
    "for ep in range(N_EPOCHS):\n",
    "    train_loss_avg.append(0)\n",
    "    num_batches = 0\n",
    "    \n",
    "    for x, y in train_iter:\n",
    "        # Update the gradient to zero \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass \n",
    "        # Encoder\n",
    "#         mu_z, std_z = encoder(x, y)\n",
    "        mu_z, std_z = encoder(x)\n",
    "\n",
    "        # Sample z\n",
    "        eps = torch.randn_like(std_z)\n",
    "        z_samples = mu_z + eps * torch.exp(std_z)\n",
    "\n",
    "        # Decoder\n",
    "#         mu_x, std_x = decoder(z_samples, y)\n",
    "        mu_x, std_x = decoder(z_samples)\n",
    "        eps = torch.randn_like(std_x)\n",
    "\n",
    "#         x_samples = mu_x + eps * torch.exp(std_x)\n",
    "\n",
    "#         return mu_z, std_z, z_samples, mu_x, std_x, x_samples\n",
    "        \n",
    "        # Loss \n",
    "        loss = loss_fn(mu_z, std_z, z_samples, mu_x, std_x, x)\n",
    "        \n",
    "        # Backward pass \n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_avg[-1] += loss.item()\n",
    "    \n",
    "        num_batches += 1\n",
    "    \n",
    "    train_loss_avg[-1] /= num_batches\n",
    "    \n",
    "    mu_z, std_z = encoder(X_test)\n",
    "    \n",
    "    eps = torch.randn_like(std_z)\n",
    "    z_samples = mu_z + eps * torch.exp(std_z)\n",
    "\n",
    "    mu_x, std_x = decoder(z_samples)\n",
    "    eps = torch.randn_like(std_x)\n",
    "\n",
    "    loss = loss_fn(mu_z, std_z, z_samples, mu_x, std_x, X_test)\n",
    "\n",
    "    test_losses.append(loss.item())\n",
    "    \n",
    "    print(\"Epoch [%d / %d] average loss: %f\" % (ep+1, N_EPOCHS, train_loss_avg[-1]))\n",
    "    print(\"Epoch [%d / %d] test loss: %f\" % (ep+1, N_EPOCHS, test_losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(train_loss_avg)\n",
    "plt.title(\"Train Losses\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(test_losses)\n",
    "plt.title(\"Test Losses\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function \n",
    "$$\n",
    "\\log p(x_i) \\geq \\int q_\\theta(z|x_i) [\\log p_\\phi(x_i|z) + \\log p(z) - \\log q_\\theta(z|x_i)] dz\\\\\n",
    "\\approx - \\frac{1}{S} \\sum_{i=1}^{S} [\\log q_\\theta(z|x_i) - \\log p_\\phi(x_i|z) - \\log p(z)]\\\\\n",
    "= -\\frac{1}{S} \\sum_{i=1}^S [\\mathcal{N}(z|\\mu(x_i), \\sigma(x_i))- \\mathcal{N}(x_i|\\mu(z), \\sigma(z)) - \\mathcal{N}(z|0, 1)]\n",
    "$$\n",
    "We add a negative sign to the loss function because the lower bound should be maximized while the loss function should be minimized.\n",
    "\n",
    "### Test evaluation metrics\n",
    "$$\n",
    "\\log p(x_i) \\geq \\int q_\\theta(z|x_i) [\\log p_\\phi(x_i|z) + \\log p(z) - \\log q_\\theta(z|x_i)] dz\\\\\n",
    "\\approx - \\frac{1}{S} \\sum_{i=1}^{S} [\\log p_\\phi(x_i|z)]\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "Should I set $q_\\theta(z|x_i)$ to $\\mathcal{N}(z|0,1)$ if I am testing with $z\\sim q(z)$? So the test evaluation would just be on the term $\\log p_\\phi(x_i|z)$.\n",
    "I will be using my trained cVAE for predicting $x$ given just the label. It make sense to test in an environment same as how I will be using the model. So I should just find the error caused by the decoder. \n",
    "\n",
    "Referenced for loss function:\n",
    "https://medium.com/retina-ai-health-inc/variational-inference-derivation-of-the-variational-autoencoder-vae-loss-function-a-true-story-3543a3dc67ee\n",
    "\n",
    "Tutorial referenced:\n",
    "https://colab.research.google.com/github/smartgeometry-ucl/dl4g/blob/master/variational_autoencoder.ipynb#scrollTo=LKnr0LCMhEGj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "test_iter = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(mu_x, std_x, x_in):\n",
    "    S = x_in.shape[0]\n",
    "    \n",
    "    # log likelihood p(x|z)\n",
    "    p_x_dist = torch.distributions.Normal(mu_x, torch.exp(std_x))\n",
    "    log_p_x = p_x_dist.log_prob(x_in)\n",
    "    \n",
    "    loss = - (1 / S) * (torch.sum(log_p_x))\n",
    "    \n",
    "    return loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = X_test.shape[0]\n",
    "# # Forward pass \n",
    "p_z_given_x = torch.distributions.Normal(0, 1)\n",
    "z = p_z_given_x.sample((S, LATENT_DIM)).type(torch.float64)\n",
    "# mu_x, std_x = decoder(z, Y_test)   \n",
    "mu_x, std_x = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = torch.distributions.Normal(0, 1).sample(std_x.shape)\n",
    "x_samples = mu_x + std_x * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test.mean(0).detach().numpy(), x_samples.mean(0).detach().numpy())\n",
    "plt.title(\"VAE Mean Comparison\")\n",
    "plt.xlabel(\"Mean of Held Out Data\")\n",
    "plt.ylabel(\"Mean of Generated Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test.std(0).detach().numpy(), x_samples.std(0).detach().numpy())\n",
    "plt.title(\"VAE Standard Deviation Comparison\")\n",
    "plt.xlabel(\"Standard Deviation of Held Out Data\")\n",
    "plt.ylabel(\"Standard Deviation of Generated Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figs, axs = plt.subplots(x_samples.shape[1], 2, figsize=(20, 100))\n",
    "# for i in range(x_samples.shape[1]):\n",
    "#     axs[i].scatter([x_test[:,i], x_samples[:,i]], color=['red','green'])\n",
    "#     axs[i].legend([\"data\", \"sample\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_test = X_test.detach().numpy()\n",
    "mu_x = mu_x.detach().numpy()\n",
    "figs, axs = plt.subplots(4, 4, figsize=(30, 30))\n",
    "count = 0 \n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        if i*4+j >= 13: \n",
    "            break \n",
    "        axs[i, j].scatter(x_test[:,i*4+j], mu_x[:,i*4+j])\n",
    "        axs[i, j].set_title(bos.feature_names[i*4+j])\n",
    "        axs[i, j].set_ylabel(\"mu_x (sampled from model)\")\n",
    "        axs[i, j].set_xlabel(\"x_in (held out dataset)\")\n",
    "    if i*4+j >= 13: \n",
    "        break \n",
    "\n",
    "plt.delaxes(ax= axs[3,1]) \n",
    "plt.delaxes(ax= axs[3,2]) \n",
    "plt.delaxes(ax= axs[3,3]) \n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples = x_samples.detach().numpy()\n",
    "figs, axs = plt.subplots(x_samples.shape[1], 2, figsize=(20, 100))\n",
    "for i in range(x_samples.shape[1]):\n",
    "    axs[i, 0].hist(x_test[:,i])\n",
    "    axs[i, 1].hist(x_samples[:,i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.std(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the 13 features \n",
    "2. What does plotting the histogram represent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(X_test, rowvar=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(x_samples, rowvar=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(X_test, rowvar=False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(x_samples, rowvar=False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(X_test, rowvar=False)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(x_samples, rowvar=False)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(X_test, rowvar=False)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(x_samples, rowvar=False)[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
