{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, label_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = nn.Linear(input_dim + label_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.hidden = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.mu_z = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.std_z = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        out = self.input(torch.cat((x, label), -1))\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.hidden(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out)\n",
    "        mu_z = self.mu_z(out)\n",
    "        std_z = self.std_z(out)\n",
    "\n",
    "        return mu_z, std_z\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, label_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = nn.Linear(latent_dim + label_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.hidden = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.mu_x = nn.Linear(hidden_dim, output_dim)\n",
    "        self.std_x = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, z, label):\n",
    "        out = self.input(torch.cat((z, label), -1))\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.hidden(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out)\n",
    "        mu_x = self.mu_x(out)\n",
    "        std_x = self.std_x(out)\n",
    "\n",
    "        return mu_x, std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos = load_boston()\n",
    "df = pd.DataFrame(bos.data)\n",
    "df.columns = bos.feature_names\n",
    "df[\"Price\"] = bos.target\n",
    "\n",
    "data = df[df.columns[:-1]]\n",
    "data = data.apply(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "\n",
    "data[\"Price\"] = df.Price\n",
    "\n",
    "# Dataset to numpy\n",
    "X = torch.tensor(data.drop(\"Price\", axis=1).values).type(torch.float64)\n",
    "Y = torch.tensor(data[\"Price\"].values).type(torch.float64)\n",
    "\n",
    "# Split dataset for test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3,\n",
    "                                                    random_state=42)\n",
    "Y_train = Y_train.view(-1, 1)\n",
    "Y_test = Y_test.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(mu_z, std_z, z_sample, mu_x, std_x, x_in):\n",
    "    S = x_in.shape[0]\n",
    "    \n",
    "    # log posterior q(z|x)\n",
    "    q_z_dist = torch.distributions.Normal(mu_z, torch.exp(std_z))\n",
    "    log_q_z = q_z_dist.log_prob(z_sample)\n",
    "    \n",
    "    # log likelihood p(x|z)\n",
    "    p_x_dist = torch.distributions.Normal(mu_x, torch.exp(std_x))\n",
    "    log_p_x = p_x_dist.log_prob(x_in)\n",
    "    \n",
    "    # log prior \n",
    "    p_z_dist = torch.distributions.Normal(0, 1)\n",
    "    log_p_z = p_z_dist.log_prob(z_sample)\n",
    "    \n",
    "    loss = (1 / S) * (\n",
    "        torch.sum(log_q_z) - torch.sum(log_p_x) - torch.sum(log_p_z) \n",
    "    )\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "N_EPOCHS = 50     # N_EPOCHS = 100 overfitted the data so the evaluation was very bad \n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001\n",
    "INPUT_DIM = X_train.shape[1]\n",
    "LABEL_DIM = Y_train.shape[1]\n",
    "LATENT_DIM = 5\n",
    "HIDDEN_DIM = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_iter = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(INPUT_DIM, LABEL_DIM, HIDDEN_DIM, LATENT_DIM).type(torch.float64)\n",
    "decoder = Decoder(LATENT_DIM, LABEL_DIM, HIDDEN_DIM, INPUT_DIM).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 50] average reconstruction error: 85.140703\n",
      "Epoch [2 / 50] average reconstruction error: 73.460292\n",
      "Epoch [3 / 50] average reconstruction error: 71.446435\n",
      "Epoch [4 / 50] average reconstruction error: 67.379344\n",
      "Epoch [5 / 50] average reconstruction error: 63.712880\n",
      "Epoch [6 / 50] average reconstruction error: 62.025782\n",
      "Epoch [7 / 50] average reconstruction error: 60.188840\n",
      "Epoch [8 / 50] average reconstruction error: 58.551060\n",
      "Epoch [9 / 50] average reconstruction error: 58.474609\n",
      "Epoch [10 / 50] average reconstruction error: 57.384165\n",
      "Epoch [11 / 50] average reconstruction error: 56.647861\n",
      "Epoch [12 / 50] average reconstruction error: 56.014024\n",
      "Epoch [13 / 50] average reconstruction error: 55.372546\n",
      "Epoch [14 / 50] average reconstruction error: 54.604355\n",
      "Epoch [15 / 50] average reconstruction error: 54.241739\n",
      "Epoch [16 / 50] average reconstruction error: 53.753541\n",
      "Epoch [17 / 50] average reconstruction error: 52.646531\n",
      "Epoch [18 / 50] average reconstruction error: 52.109132\n",
      "Epoch [19 / 50] average reconstruction error: 52.240089\n",
      "Epoch [20 / 50] average reconstruction error: 51.542025\n",
      "Epoch [21 / 50] average reconstruction error: 51.324131\n",
      "Epoch [22 / 50] average reconstruction error: 50.637757\n",
      "Epoch [23 / 50] average reconstruction error: 50.795188\n",
      "Epoch [24 / 50] average reconstruction error: 50.271062\n",
      "Epoch [25 / 50] average reconstruction error: 49.789771\n",
      "Epoch [26 / 50] average reconstruction error: 49.347852\n",
      "Epoch [27 / 50] average reconstruction error: 48.758926\n",
      "Epoch [28 / 50] average reconstruction error: 48.517895\n",
      "Epoch [29 / 50] average reconstruction error: 48.204501\n",
      "Epoch [30 / 50] average reconstruction error: 48.081916\n",
      "Epoch [31 / 50] average reconstruction error: 48.072614\n",
      "Epoch [32 / 50] average reconstruction error: 47.352332\n",
      "Epoch [33 / 50] average reconstruction error: 47.066611\n",
      "Epoch [34 / 50] average reconstruction error: 47.059526\n",
      "Epoch [35 / 50] average reconstruction error: 46.517052\n",
      "Epoch [36 / 50] average reconstruction error: 46.444336\n",
      "Epoch [37 / 50] average reconstruction error: 46.612812\n",
      "Epoch [38 / 50] average reconstruction error: 46.076257\n",
      "Epoch [39 / 50] average reconstruction error: 46.028787\n",
      "Epoch [40 / 50] average reconstruction error: 45.548176\n",
      "Epoch [41 / 50] average reconstruction error: 45.762407\n",
      "Epoch [42 / 50] average reconstruction error: 44.891766\n",
      "Epoch [43 / 50] average reconstruction error: 44.767358\n",
      "Epoch [44 / 50] average reconstruction error: 44.578424\n",
      "Epoch [45 / 50] average reconstruction error: 44.173637\n",
      "Epoch [46 / 50] average reconstruction error: 44.096736\n",
      "Epoch [47 / 50] average reconstruction error: 43.685511\n",
      "Epoch [48 / 50] average reconstruction error: 44.076067\n",
      "Epoch [49 / 50] average reconstruction error: 43.246771\n",
      "Epoch [50 / 50] average reconstruction error: 43.291063\n"
     ]
    }
   ],
   "source": [
    "train_loss_avg = []\n",
    "\n",
    "\n",
    "for ep in range(N_EPOCHS):\n",
    "    train_loss_avg.append(0)\n",
    "    num_batches = 0\n",
    "    \n",
    "    for x, y in train_iter:\n",
    "        # Update the gradient to zero \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass \n",
    "        # Encoder\n",
    "        mu_z, std_z = encoder(x, y)\n",
    "\n",
    "        # Sample z\n",
    "        eps = torch.randn_like(std_z)\n",
    "        z_samples = mu_z + eps * torch.exp(std_z)\n",
    "\n",
    "        # Decoder\n",
    "        mu_x, std_x = decoder(z_samples, y)\n",
    "        eps = torch.randn_like(std_x)\n",
    "\n",
    "        x_samples = mu_x + eps * torch.exp(std_x)\n",
    "\n",
    "#         return mu_z, std_z, z_samples, mu_x, std_x, x_samples\n",
    "        \n",
    "        # Loss \n",
    "        loss = loss_fn(mu_z, std_z, z_samples, mu_x, std_x, x)\n",
    "        \n",
    "        # Backward pass \n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_avg[-1] += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    print(\"Epoch [%d / %d] average reconstruction error: %f\" % (ep+1, N_EPOCHS, train_loss_avg[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(train_loss_avg)\n",
    "plt.title(\"Train Losses\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function \n",
    "$$\n",
    "\\log p(x_i) \\geq \\int q_\\theta(z|x_i) [\\log p_\\phi(x_i|z) + \\log p(z) - \\log q_\\theta(z|x_i)] dz\\\\\n",
    "\\approx - \\frac{1}{S} \\sum_{i=1}^{S} [\\log q_\\theta(z|x_i) - \\log p_\\phi(x_i|z) - \\log p(z)]\\\\\n",
    "= -\\frac{1}{S} \\sum_{i=1}^S [\\mathcal{N}(z|\\mu(x_i), \\sigma(x_i))- \\mathcal{N}(x_i|\\mu(z), \\sigma(z)) - \\mathcal{N}(z|0, 1)]\n",
    "$$\n",
    "We add a negative sign to the loss function because the lower bound should be maximized while the loss function should be minimized.\n",
    "\n",
    "### Test evaluation metrics\n",
    "$$\n",
    "\\log p(x_i) \\geq \\int q_\\theta(z|x_i) [\\log p_\\phi(x_i|z) + \\log p(z) - \\log q_\\theta(z|x_i)] dz\\\\\n",
    "\\approx - \\frac{1}{S} \\sum_{i=1}^{S} [\\log p_\\phi(x_i|z)]\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "Should I set $q_\\theta(z|x_i)$ to $\\mathcal{N}(z|0,1)$ if I am testing with $z\\sim q(z)$? So the test evaluation would just be on the term $\\log p_\\phi(x_i|z)$.\n",
    "I will be using my trained cVAE for predicting $x$ given just the label. It make sense to test in an environment same as how I will be using the model. So I should just find the error caused by the decoder. \n",
    "\n",
    "Referenced for loss function:\n",
    "https://medium.com/retina-ai-health-inc/variational-inference-derivation-of-the-variational-autoencoder-vae-loss-function-a-true-story-3543a3dc67ee\n",
    "\n",
    "Tutorial referenced:\n",
    "https://colab.research.google.com/github/smartgeometry-ucl/dl4g/blob/master/variational_autoencoder.ipynb#scrollTo=LKnr0LCMhEGj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "test_iter = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(mu_x, std_x, x_in):\n",
    "    S = x_in.shape[0]\n",
    "    \n",
    "    # log likelihood p(x|z)\n",
    "    p_x_dist = torch.distributions.Normal(mu_x, torch.exp(std_x))\n",
    "    log_p_x = p_x_dist.log_prob(x_in)\n",
    "    \n",
    "    loss = - (1 / S) * (torch.sum(log_p_x))\n",
    "    \n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch: 1 Loss: 14.900144751875878\n",
      "Test Epoch: 2 Loss: 15.961965517481945\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(test_iter):\n",
    "    # Forward pass \n",
    "    p_z_given_x = torch.distributions.Normal(0, 1)\n",
    "    z = p_z_given_x.sample((x.shape[0], LATENT_DIM))\n",
    "    mu_x, std_x = decoder(z, y)\n",
    "    \n",
    "    # Loss \n",
    "    loss = eval_metrics(mu_x, std_x, x)       # what is mu_z and std_z in this case? \n",
    "        # Model assumes that z is sampled independently or x in test time therefore should sample from N(0, 1)\n",
    "    \n",
    "    print(\"Test Epoch: {} Loss: {}\".format(i + 1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
